# ThreadPool Executor
## Java Blocking Queue
È un'interfaccia della libreria `Java.util.concurrent`. Implementa una coda FIFO.
### Qual è la differenza con la `Queue<T>`?
La Blocking Queue è pensata per essere usata in un ambiente multithread. È "MT-safe", infatti garantisce:
1. Mutua esclusione.
2. Se è piena e *Thread1* pusha $\implies$ Si blocca.
3. Se è vuota e *Thread2* rimuove $\implies$ Si blocca.
```java
import java.util.concurrent.ArrayBlockingQueue; 
import java.util.concurrent.BlockingQueue; 
import java.util.concurrent.LinkedBlockingQueue; 

public class BlockingQueueExample { 
	public static void main(String[] args) {
		BlockingQueue arrayBlockingQueue = new ArrayBlockingQueue(3); 
		BlockingQueue linkedBlockingQueue = new LinkedBlockingQueue();
	}
}
```
### Array Blocking Queue
Coda di lunghezza fissata, memorizza gli elementi in un array circolare. C'è una sola lock per tutto l'array. Non sono possibili inserzioni/rimozioni in parallelo. Essendo essenzialmente un array, non viene creato un ulteriore oggetto.
![[array_blocking_queue.png]]
### Linked Blocking Queue
Lista di dimensione limitata o illimitata (ovviamente nei limiti della macchina). Ci sono lock separate per lettura e scrittura, quindi più thread possono accedervi in parallelo. Mantiene gli elementi in una linked list, viene creato un nuovo elemento per ogni inserzione.
![[linked_blocking_queue.png]]
### Metodi Blocking Queue
Abbiamo 4 diversi metodi per: Inserire, rimuovere o esaminare un elemento della coda.

| |Lancia eccezioni|Valori speciali|Bloccante|Times out|
|--|--|--|--|--|
|Insert|`add(obj)`|`offer(obj)`|`put(obj)`|`offer(obj, timeout, timeunit)`|
|Remove|`remove(obj)`|`poll()`|`take()`|`poll(timeout, timeunit)`|
|Examine|`element()`|`peek()`| | |
**Insert**
- `add(obj)`. Inserisce l'elemento specificato in questa coda se è possibile farlo immediatamente senza violare i limiti di capacità, restituendo `true` in caso di successo e lanciando una IllegalStateException se non c'è spazio disponibile.
- `offer(obj)`. Come `add` ma non lancia un'eccezione in caso di coda piena, si limita a restituire `false`.
- `put(obj)`. Inserisce l'elemento specificato in questa coda, aspettando, se necessario, che si liberi spazio. Chiaramente a differenza dei due metodi sopra, questo è **bloccante**.
- `offer(obj, timeout, timeunit)`. Inserisce l'elemento specificato in questa coda, attendendo fino al tempo di attesa specificato, se necessario, affinché lo spazio sia disponibile.

**Remove**
- `remove(obj)`. Rimuove una singola istanza dell'elemento specificato da questa coda, se è presente. Altrimenti lancia un'eccezione.
- `poll()`. Recupera e rimuove la testa di questa coda. Restituisce la testa di questa coda, o `null` se vuota.
- `take()`. Recupera e rimuove la testa di questa coda, aspettando, se necessario, che un elemento sia disponibile.
- `poll(timeout, timeunit)`. Recupera e rimuove la testa di questa coda, attendendo fino al tempo di attesa specificato, se necessario, che un elemento sia disponibile. 

**Examine**
- `element()`. Recupera, ma non rimuove, la testa di questa coda. Questo metodo differisce da `peek` solo perché lancia un'eccezione se la coda è vuota.
- `peek()`. Recupera, ma non rimuove, la testa di questa coda o restituisce `null` se la coda è vuota.
## Thread Pool Executor
È una classe che permette di creare un thread pool personalizzato con parametri che possiamo passare al suo costruttore:
```java
import java.util.concurrent.*; 
public class ThreadPoolExecutor implements ExecutorService {
	public ThreadPoolExecutor 
		(int CorePoolSize, 
		 int MaximumPoolSize, 
		 long keepAliveTime, 
		 TimeUnit unit, 
		 BlockingQueue workqueue, 
		 RejectedExecutionHandler handler)
}
```
Nello specifico, `CorePoolSize`, `MaximumPoolSize` e `keepAliveTime` servono per la gestione dei thread del pool:
- `CorePoolSize`. Nucleo dei thread attivabili al momento della creazione del pool con `prestartAllCoreThreads()`.
- `MaximumPoolSize`. Numero di thread attivabili se necessario (on demand).
- `keepAliveTime`. Vale per i thread non appartenenti al core. Se il thread *T1* è inattivo per troppo tempo, allora viene ucciso dal pool.
- `workqueue` è una struttura dati necessaria per memorizzare gli eventuali tasks in attesa di esecuzione.

![[thread_pool_executor.png]]

Il core è il nucleo minimo di thread attivi nel pool. I thread del core possono essere attivati:
- tutti al momento della creazione del pool: `PrestartAllCoreThreads( )`.
- on demand, al momento della sottomissione di un nuovo task, anche se qualche thread già creato del core è inattivo. 
- quando tutti i threads sono stati creati, la politica cambia.
### Elasticità
Abbiamo un `keepAliveTime` per i thread non appartenenti al core. Si considera il timeout `T` specificato al momento della costruzione del ThreadPool mediante la definizione di:
- un valore (es: 50000).
- l'unità di misura utilizzata (es: TimeUnit. MILLISECONDS).

Se nessun task viene sottomesso entro `T`, il thread termina la sua esecuzione, riducendo così il numero di threads del pool. La dimensione del ThreadPool non scende mai sotto Core pool size. Vi è un'unica eccezione: `allowCoreThreadTimeOut(boolean value)` invocato con il parametro settato a `true`.
Quindi se tutti i thread del core sono già stati creati e viene sottomesso un nuovo task:
```ad-warning
title: se un thread del core è inattivo, il task viene assegnato ad esso
Se tutti i thread del core stanno eseguendo un task e la coda non è piena , il nuovo task viene inserito nella coda: i task verranno quindi poi prelevati dalla coda ed inviati ai thread disponibili.
```

```ad-warning
title: se tutti i thread del core stanno eseguendo un task e la coda è piena
Si crea un nuovo thread attivando così k thread: $corePoolSize\leq k \leq MaxPoolSize$.
```

```ad-warning
title: se coda è piena e sono attivi $n = MaxPoolSize$ threads
Il task viene respinto.
```

`KeepAlive = 0` secondi corrisponde a “KeepAlive non significativo”, il thread non viene mai disattivato. 
### Istanze di ThreadPoolExecutors
![[thread_pool_exec_instance.png]]

Poi abbiamo:
- `SingleThreadedExecutor`. Con singolo thread, è l'equivalente di invocare un `FixedThreadPool` di dimensione 1. Viene usata per assicurare che i thread del pool vengano eseguiti nell'ordine con cui si trovano in coda (sequenzialmente).
- `ScheduledThreadPool`. Per distanziare esecuzione dei task con un certo delay, trova buona applicazione per task periodici.

## Rejection 
![[rejection.png]]

Come viene gestito il rifiuto di un task? Possiamo fornire una *rejection policy*:
1. `AbortPolicy`. Politica di default, consiste nel sollevare `RejectedExecutionException`.
2. `DiscardPolicy, DiscardOldestPolicy, CallerRunsPolicy`. vedi API.
3. Definire un **custom rejection handler** implementando l'interfaccia `RejectExecutionHandler` ed il metodo `rejectedExecution`.

Esempio di gestione del rifiuto di un task:
```java
import java.util.concurrent.*; 
public class RejectedException { 
	public static void main (String[] args ) {
		ExecutorService service = new ThreadPoolExecutor
				(10, 
				 12, 
				 120, 
				 TimeUnit.SECONDS, 
                 new ArrayBlockingQueue(3)); 
		for (int i=0; i<20; i++){ 
			try { 
				service.execute(new Task(i)); 
			} catch (RejectedExecutionException e) {
				System.out.println("task rejected" + e.getMessage());
			} 
		}
	}
}
```
## Terminazione dei thread
La JVM termina quando tutti i thread (non daemon) terminano. Quando abbiamo un thread Pool, i task vengono eseguiti in modo asincrono rispetto alla loro sottomissione (alcuni task precedentemente sottomessi potrebbero ancora essere in coda).
Poichè alcuni threads possono essere sempre attivi, JAVA mette a disposizione dell'utente alcuni metodi che permettono di terminare l'esecuzione del pool.
```ad-note 
title: Terminazione graduale
Finisci il lavoro, non prendere più task e termina. Metodo `service.shutdown()`.
```
```ad-note 
title: Terminazione brutale
Termina subito e restituisce una lista con i `runnable` all'interno della coda non ancora sottomessi. Metodo `service.shutdownNow()`.
```
## Dimensione ideale del thread pool
- Quando abbiamo task **CPU-bound** $\implies$ la dimensione ottimale del pool è uguale al numero di cores della CPU.
- Quando abbiamo task **I/O bound** $\implies$ un numero di thread maggiore del numero di CPU cores può aumentare le performance della applicazione.
