Table of contents

1. [[#Formulazione del problema|Formulazione del problema]]
1. [[#Algoritmi di ricerca|Algoritmi di ricerca]]
	1. [[#Algoritmi di ricerca#Misura delle prestazioni|Misura delle prestazioni]]
	1. [[#Algoritmi di ricerca#Caso studio: Itinerario|Caso studio: Itinerario]]
	1. [[#Algoritmi di ricerca#Caso studio: Gioco dell'otto|Caso studio: Gioco dell'otto]]
	1. [[#Algoritmi di ricerca#Caso studio: Le otto regine|Caso studio: Le otto regine]]
1. [[#Ricerca della soluzione|Ricerca della soluzione]]
	1. [[#Ricerca della soluzione#Ricerca ad albero|Ricerca ad albero]]
	1. [[#Ricerca della soluzione#Nodi dell'albero di ricerca|Nodi dell'albero di ricerca]]
	1. [[#Ricerca della soluzione#Struttura dati per la frontiera|Struttura dati per la frontiera]]
	1. [[#Ricerca della soluzione#Esempi di strategie di ricerca|Esempi di strategie di ricerca]]
	1. [[#Ricerca della soluzione#Valutazione di una strategia|Valutazione di una strategia]]
1. [[#Strategie di ricerca non informata|Strategie di ricerca non informata]]
	1. [[#Strategie di ricerca non informata#Ricerca BF (in ampiezza)|Ricerca BF (in ampiezza)]]
		1. [[#Ricerca BF (in ampiezza)#Complessità di BF|Complessità di BF]]
	1. [[#Strategie di ricerca non informata#Ricerca DF (Depth-first)|Ricerca DF (Depth-first)]]
	1. [[#Strategie di ricerca non informata#DL (Depth-limited)|DL (Depth-limited)]]
	1. [[#Strategie di ricerca non informata#Approfondimento iterativo (ID)|Approfondimento iterativo (ID)]]
	1. [[#Strategie di ricerca non informata#Direzione della ricerca|Direzione della ricerca]]
	1. [[#Strategie di ricerca non informata#Ricerca bidirezionale|Ricerca bidirezionale]]
	1. [[#Strategie di ricerca non informata#Excursus: Cammini ciclici nella ricerca|Excursus: Cammini ciclici nella ricerca]]
		1. [[#Excursus: Cammini ciclici nella ricerca#Soluzioni|Soluzioni]]
	1. [[#Strategie di ricerca non informata#Ricerca di costo uniforme (UC)|Ricerca di costo uniforme (UC)]]
	1. [[#Strategie di ricerca non informata#Tabellozza di riepilogo|Tabellozza di riepilogo]]


Gli agenti di problem-solving o risolutori di problemi:
- Adottano il paradigma della risoluzione di problemi come ricerca in uno spazio di stati (problem solving).
- Sono agenti con **modello** (storia percezioni e stati) che adottano una rappresentazione atomica dello stato.
- Sono particolari agenti con **obiettivo**, che pianificano l’intera sequenza di mosse prima di agire.

```ad-def
title: Processo di risoluzione
Ha 4 passi da seguire:
1. Determinazione dell'obiettivo (cioè trovare un insieme di stati in cui l'obiettivo è soddisfatto).
2. Formulazione del problema (rappresentazione degli stati e rappresentazione delle azioni).
3. Determinazione della soluzione mediante ricerca (un piano).
4. Esecuzione del piano (soluzione algoritmica).
```
e.g Viaggio con mappa:
1. Raggiungere Bucarest
2. $Azioni = \textit{Guidare da una città all'altra}$; $Stato = \textit{Città sulla mappa}$.

```ad-help
Bisogna fare delle assunzioni:
- Ambiente statico (il mondo non cambia mentre l’agente decide l’azione, non varia nel tempo)
- Osservabile (so dove sono)
- Discreto (insieme finito di azioni possibili)
- Deterministico ($1\textit{ azione} \to 1\textit{ risultato}$), si assume che l'agente possa eseguire il piano "ad occhi chiusi", niente può andare storto (e.g da A arrivo sicuramente in B).
```
## Formulazione del problema
 Un problema può essere definito formalmente mediante cinque componenti:
 1. Stato iniziali.
 2. Azioni possibili in s: $Azioni(s)$ dove $s = stato$
 3. Modello di transizione: 
	 - $Risultato:\textit{stato}\times\textit{azione}\to\textit{stato}$
	 - $Risultato(s,a) = s'$ con $s'$ detto "stato **successore**".
4. Test obiettivo: funzione che dato uno stato restituisce un booleano in base all'obiettivo $\textit{goal-test}:stato\to\{true,false\}$
5. Costo del cammino: somma dei costi delle azioni (costo dei passi) dove
	- costo di un azione: $c(s,a,s')$ dove $a$ è un'azione.
	- il costo di un azione è sempre non negativo, $c(s,a,s') \geq 0$.

(1), (2) e (3) definiscono implicitamente lo **spazio degli stati**. 
- Definirlo esplicitamente può essere molto dispendioso.

## Algoritmi di ricerca
> Il processo che cerca una sequenza di azioni che raggiunge l’obiettivo è detto ricerca

Gli algoritmi di ricerca prendono in input un problema e restituiscono un cammino soluzione. 
e.g un cammino che porta dallo stato iniziale a uno stato goal

### Misura delle prestazioni
Trova una soluzione? Quanto costa trovarla? Quanto efficiente è la soluzione?
In generale possiamo affermare che il costo totale di un algoritmo equivale alla somma del costo della ricerca e del costo del cammino trovato:
$$ \textit{Costo totale} = \textit{Costo della ricerca} +  
\textit{Costo del cammino soluzione} $$

Ne viene che se $\textit{Costo della ricerca} > \textit{Costo del cammino soluzione}$ allora l'algoritmo utilizzato è poco efficiente.

### Caso studio: Itinerario
Vogliamo trovare il percorso più breve (in km) da una città di partenza a una città di arrivo. In questo caso vogliamo arrivare a Bucarest partendo da Arad.

![[problema_itinerario.png]]

```ad-note
title: Formulazione
- Stati: le città (e.g `In(Pitesti)`)
	1. Stato iniziale. Città da cui si parte. `In(Arad)`
	2. Azioni. Spostarsi da una città all'altra, devono essere collegate.
	 `Azioni(In(Arad)) ={Go(Sibiu), Go(Zerind) ...}`
	3. Modello di transizione. `Risultato(In(Arad), Go(Sibiu)) = In(Sibiu)`.
	4. Test Obiettivo: `{In(Bucarest)}`.
	5. Costo del cammino: somma lunghezze strade.
- Lo spazio degli stati coincide con il grafo di collegamenti tra le città.
```

### Caso studio: Gioco dell'otto

![[problema_gioco8.png]]

```ad-note
title: Formulazione
- Stati: possibili configurazioni della scacchiera
	1. Stato iniziale: una configurazione
    2. Obiettivo: una configurazione
    3. Goal-Test: Stato obiettivo?
    4. Azioni: mosse della casella bianca (su, giù, sinistra, destra)
    5. Costo cammino: ogni passo costa 1
- Lo spazio degli stati è un grafo con possibili cicli.
- È un problema NP-completo, per 8 tasselli abbiamo $\dfrac{9!}{2}=181'000$ stati.
```

### Caso studio: Le otto regine
Collocare otto regine sulla scacchiera in modo tale che nessuna regina sia attaccata da altre.

![[problema_8regine.png]]

Abbiamo diverse formulazioni possibili:

```ad-note
title: Formulazione incrementale I
- Stati: scacchiere con 0-8 regine
	1. Goal-Test: 8 regine sulla scacchiera, nessuna attaccata.
	2. Costo cammino: zero (resta 8, per le 8 mosse effettive, e non è rilevante, interessa solo lo stato finale).
	3. Azioni: aggiungi una regina
	4. Spazio stati: $64 \cdot 63 \cdot \ldots \cdot 57 \sim 1.8 \cdot 10^{14}$ possibili sequenze da considerare.
```

```ad-note
title: Formulazione incrementale II
- Stati: scacchiere con 0-8 regine, **nessuna mincacciata**
	1. Goal-Test: 8 regine sulla scacchiera, nessuna attaccata.
	2. Costo cammino: zero (resta 8, per le 8 mosse effettive, e non è rilevante, interessa solo lo stato finale).
	3. Azioni: aggiungi una regina **nella colonna vuota più a destra ancora libera in modo che non sia minacciata**
	4. Spazio stati: $2057$ possibili sequenze da considerare.
```


```ad-note
title: Formulazione a stato completo
- Stati: scacchiere con 0-8 regine, una per colonna.
	1. Goal-Test: 8 regine già sulla scacchiera, nessuna minacciata
	2. Costo cammino: zero.
	3. Azioni: sposta una regina nella colonna, se minacciata.
```

In generale: $\textit{formulazioni diverse}\implies\textit{spazi di stati diversi}$.

## Ricerca della soluzione
Consiste nella generazione di un albero di ricerca sovrapposto allo spazio degli stati (generato da possibili sequenze di azioni). 

![[romania_1.png]]

```ad-def
title: Ricerca
Approfondire un’opzione, mettere da parte le altre e ripredenderle se non trova soluzione.
```

Espandendo un nodo viene generata una frontiera a partire da esso:

![[romania_2.png]]

### Ricerca ad albero
Ossia senza controllare se i nodi (stati) siano già stati esplorati.

```javascript
function RicercaAlbero (problema) { 
	Inizializza la frontiera con stato iniziale del problema;
	loop do  
		if (la frontiera è vuota)
			return fallimento;  
		Scegli un nodo u foglia da espandere; 
		Rimuovi u dalla frontiera;
		if u contiene uno stato obiettivo
			return soluzione corrispondente;
		Espandi il nodo u;
		Aggiungi i successori di u alla frontiera;
}
```

La scelta del nodo da espandere rappresenta la nostra strategia di ricerca.

### Nodi dell'albero di ricerca
Un nodo $v$ è una struttura dati con quattro componenti:
- **Uno stato.** `v.stato`
- **Nodo padre.** `v.padre`
- **Azione effettuata per generarlo.** `v.azione`
- **Costo del cammino dalla radice a v.** `v.costoCammino` indicata con $g(v)$

$$g(v) = \textit{v.padre.costoCammino}+\textit{costoUltimoPasso}$$

### Struttura dati per la frontiera
```ad-def
title: Frontiera
Lista dei nodi in attesa di essere espansi (le foglie dell’albero di ricerca).
```
La frontiera è implementata come una coda con operazioni:
- `isEmpty()`.
- `pop()`, estrae il primo elemento.
- `push(el, coda)`.

### Esempi di strategie di ricerca
```ad-def
title: Breadth-first
Con coda implementata FIFO. Viene estratto l’elemento più vecchio (in attesa da più tempo); in nuovi nodi sono aggiunti alla fine.
```

```ad-def
title: Depth-first
Con coda implementata LIFO. Viene estratto il più recentemente inserito; i nuovi nodi sono inseriti all’inizio (pila).
```

```ad-def
title: UC (uniform cost) e altri...
Con coda con priorità. Viene estratto quello con priorità più alta in base a una funzione di ordinamento; dopo l’inserimento dei nuovi nodi si riordina.
```

Fin'ora abbiamo elencato strategie **non informate**:
- Ricerca in ampiezza (BF)  
- Ricerca in profondità (DF)  
- Ricerca in profondità limitata (DL)  
- Ricerca con approfondimento iterativo (ID) 
- Ricerca di costo uniforme (UC)

### Valutazione di una strategia
- **Completezza**: se la soluzione esiste viene trovata.
- **Ottimalità (ammissibilità)**: trova la soluzione migliore, con costo minore.
- **Complessità in tempo**: tempo richiesto per trovare la soluzione.
- **Complessità in spazio**: memoria richiesta.

## Strategie di ricerca non informata

### Ricerca BF (in ampiezza)
È una strategia semplice in cui il nodo radice viene espanso per primo, poi vengono espansi tutti i successori del nodo radice, poi i loro successori e così via. In generale, tutti i nodi a una determinata profondità dell'albero di ricerca vengono espansi prima di tutti i nodi al livello successivo. Come esplorare il grafo dello spazio degli stati a livelli progressivi di stessa profondità.

![[bfs_ex.png]]

La frontiera viene implementata con una coda che inserisce alla fine (FIFO):
- I nuovi nodi (che sono sempre più profondi dei loro genitori) vanno in fondo alla coda.
- I vecchi nodi, che sono meno profondi dei nuovi, vengono espansi per primi.

Il test del goal viene applicato a ogni nodo quando viene generato, anziché quando viene selezionato per l'espansione (è più efficiente, si ferma appena trova il goal, prima di espandere).

L'algoritmo scarta qualsiasi nuovo percorso verso uno stato già presente nella frontiera o nell'insieme esplorato. Pertanto, la ricerca BF ha sempre il percorso più superficiale per ogni nodo della frontiera.

#### Complessità di BF
Assumiamo:
$$b = \textit{branching} = \text{fattore di ramificazione} = \max (\# \textit{successori})$$
$$d = \textit{depth} = \text{profondità del nodo obiettivo più superficiale (più vicino all'iniziale)}$$
$$m = \textit{max} = \text{lunghezza massima dei cammini nello spazio degli stati}$$

BF è una strategia: 
- Completa.
- Ottimale $\iff$ i passi costano tutti $k$, cioè $\forall \; u.g(u) = k \cdot \text{depth}(u)$.

```ad-note
title: Complessità in tempo
La radice dell'albero genera $b$ nodi a profondità 1, ognuno dei quali genera altri $b$ nodi, per un totale di $b^2$ a profondità 2. Ognuno di questi genera altri $b$ nodi, per un totale di $b^3$ nodi a profondità 3, e così via. Supponiamo ora che la soluzione si trovi alla profondità $d$:
$$T(b,d) = b + b^2 + \ldots + b^d \sim O(b^d)$$
```

```ad-note
title: Complessità in spazio
Qualsiasi tipo di ricerca di grafi, che memorizza ogni nodo espanso nell'insieme esplorato, la complessità spaziale è sempre entro un fattore $b$ della complessità temporale. In particolare nella BF ogni nodo generato rimane in memoria.
Ci saranno $O(b^{d-1})$ nodi nell'insieme esplorato e $O(b^d)$ nodi nella frontiera, quindi la complessità spaziale è $O(b^d)$, cioè è dominata dalla dimensione della frontiera. Passare a una ricerca ad albero non farebbe risparmiare molto spazio e, in uno spazio di stati con molti percorsi ridondanti, il passaggio potrebbe costare molto tempo.
In soldoni:
$$O(b^d) \text{ per la frontiera}$$
```

```ad-warning
title: Versione ad Albero vs Versione a Grafo
- L'algoritmo ad albero non ha nessuna lista `esplorati`, mantiene solo una coda FIFO per la frontiera. Non mantenendo alcun controllo sugli esplorati potrebbe espandere nodi con stati già esplorati.
- L'algoritmo a grafo mantiene una lista `esplorati`, che contiene i nodi estratti dalla frontiera; così da poter gestire gli stati ripetuti, aggiungendo un controllo prima del test obiettivo per assicurarci che il successore del nodo espanso non sia già stato esplorato e né sia in frontiera.
```

### Ricerca DF (Depth-first)
La ricerca DF espande sempre il nodo più profondo nella frontiera corrente dell'albero. La ricerca procede al livello più profondo dell'albero, dove i nodi non hanno successori. Man mano che questi nodi vengono espansi, vengono eliminati dalla frontiera, quindi la ricerca "torna indietro" fino al nodo più profondo successivo che ha ancora successori inesplorati.

![[dfs_ex.png]]

La ricerca DF utilizza una coda LIFO, quindi per l'espansione viene scelto il nodo generato più di recente. Questo deve essere il nodo non espanso più profondo, perché è un livello più profondo del suo genitore, che a sua volta era il nodo non espanso più profondo quando è stato selezionato.

```ad-note
title: Complessità in tempo
Per uno spazio degli stati con fattore di ramificazione $b$ e profondità massima $m$, si ha 

$$O(b^m)\textit{ (che può essere }>O(b^d))$$

perché potremmo andare in profondità maggiore di quella dove sta il goal (visto che si esplora fino in fondo). Da notare che $m$ può essere infinita se l'albero è illimitato.
```

```ad-note
title: Complessità in spazio
Finora la ricerca DF non sembra avere un vantaggio rispetto alla ricerca BF, in realtà il motivo è la complessità dello spazio:
- Per una ricerca a grafo, non c'è alcun vantaggio. 
- Per una ricerca ad albero DF deve memorizzare solo un singolo percorso dalla radice a un nodo foglia, insieme ai restanti nodi fratelli non espansi per ogni nodo del percorso. Una volta che un nodo è stato espanso, può essere rimosso dalla memoria non appena tutti i suoi discendenti sono stati completamente esplorati.

Quindi la DF richiede la memorizzazione solo di $O(bm)$ nodi.
```

```ad-warning
title: Versione ad Albero vs Versione a Grafo
- Per quanto riguarda la versione ad Albero, la ricerca DF è una strategia non completa perché non c'è niente che ridiriga la ricerca nell'eventualità di un loop. Non essendo completa non è neanche ottimale.
- Nella versione a Grafo perdiamo i vantaggi di memoria perché bisogna mantenere una lista di `esplorati`, tuttavia diviene una strategia completa in spazi degli stati finiti (perché, al caso pessimo, sicuramente tutti i nodi verranno espansi); non completa in spazi infiniti.
```

```ad-def
title: DF ricorsiva
Ancora più efficiente in occupazione di memoria perché mantiene solo il cammino corrente. Cioè $O(m)$ nodi al caso pessimo; non genera prima i fratelli, genera i nodi fratelli solo quando torna indietro (al momento del backtracking). Salva lo stato su uno stack a cui torna in caso di fallimento per fare altri tentativi.
```

![[dfsBackTrack_ex.gif]]

### DL (Depth-limited)
Il fallimento della ricerca DF in spazi di stati infiniti può essere attenuato ponendo alla ricerca DF un limite di profondità predeterminato $l$. In altre parole, i nodi a profondità $l$ vengono trattati come se non avessero successori. 
- Sfortunatamente, questo rende incompleta la strategia se scegliamo $l < d$, cioè se l'obiettivo più superficiale è oltre il limite di profondità. (Questo è probabile quando non è nota $d$ ). Quindi nemmeno ottimale se scegliamo $l > d$.
- La sua complessità in tempo è $O(b^l)$ e la sua complessità in spazio è $O(bl)$.
- La DF può essere vista come un caso speciale di DL con $l=\infty$.

### Approfondimento iterativo (ID)
L'approfondimento iterativo è una strategia generale, spesso utilizzata in combinazione con la ricerca ad albero DF, che trova il miglior limite di profondità $l$. Lo fa aumentando gradualmente $l$ - prima 0, poi 1, poi 2 e così via - fino a trovare un obiettivo. Questo avviene quando il limite di profondità raggiunge $d$ (profondità del nodo obiettivo più superficiale), cioè $l=d$.
- Combina i vantaggi della ricerca DF e dell BF. 
	- Come la ricerca DF, i suoi requisiti di memoria sono $O(bd)$.
	- Come la ricerca BF, è completa quando il fattore di ramificazione $b$ è finito; è ottimale quando il costo del percorso è una funzione non decrescente (monotona) della profondità del nodo.

```ad-note
title: Ma conviene o è uno spreco?
Può sembrare uno spreco perché gli stati vengono generati più volte. Tuttavia non è troppo costoso in un albero di ricerca con lo stesso (o quasi) fattore di ramificazione $b$ a ogni livello, la maggior parte dei nodi si trova nel livello inferiore, quindi non ha molta importanza che i livelli superiori vengano generati più volte. In un'approfondimento iterativo, i nodi del livello inferiore (a profondità $d$) vengono generati una volta, quelli del livello immediatamente sopra vengono generati due volte e così via, fino ai figli della radice, che vengono generati $d$ volte. 
Quindi 
$$T(ID) = (d)\cdot b + (d-1)\cdot b^2 + \ldots (1)\cdot b^d\sim O(b^d)$$
ovviamente se esiste soluzione, se non esiste soluzione costa $O(b^m)$.
```

### Direzione della ricerca
Capire in quale direzione cercare è un probema importante, abbiamo due direzioni:
- Nella ricerca in avanti (guidata dai dati) si esplora lo spazio di ricerca dallo stato iniziale allo stato obiettivo.
- Nella ricerca all'indietro (guidata dall'obiettivo) si esplora lo spazio di ricerca a partire da uno stato goal riconducendosi a sotto-goal fino a trovare uno stato iniziale.

```ad-info
title: Quando ricercare in avanti?
- Molti obiettivi possibili. 
- Abbiamo una serie di dati da cui partire.
```

```ad-info
title: Quando ricercare all'indietro?
- Obiettivo è chiaramente definito (dimostrare un teorema) o si possono formulare una serie limitata di ipotesi.
- Dati del problema non noti e la loro acquisizione può essere guidata dall'obiettivo.
```

In generale conviene procedere nella direzione in cui il fattore di diramazione $b$ è minore.

### Ricerca bidirezionale
Si procede nelle due direzioni sperando che le due ricerche si incontrino al centro. La motivazione è che 
$$b^{d/2} + b^{d/2} < b^d$$ 

La ricerca bidirezionale viene implementata sostituendo il test dell'obiettivo con un controllo per verificare se le frontiere delle due ricerche si intersecano; se si allora è stata trovata una soluzione.
- La prima soluzione trovata potrebbe non essere ottimale, anche se le due ricerche sono entrambe di tipo BF. È necessaria un'ulteriore ricerca.

```ad-note
title: Complessità in tempo
Nell'ipotesi di ricerca BF in entrambe le direzioni è $O(b^{d/2})$, assumendo che il test intersezione costi $O(1)$ (e.g hash table).
```

```ad-note
title: Complessità in spazio
Anche la complessità in spazio è $O(b^{d/2})$. Possiamo ridurla di circa la metà se una delle due ricerche viene effettuata con un approfondimento iterativo, ma almeno una delle due frontiere deve essere mantenuta in memoria per poter effettuare il controllo dell'intersezione. Questo requisito di spazio è la debolezza più significativa della ricerca bidirezionale.
```

```ad-warning
title: Non sempre è applicabile
e.g predecessori non definiti, troppi stati obiettivo,...
```

### Excursus: Cammini ciclici nella ricerca
I cammini ciclici rendonogli alberi di ricerca infiniti. Su spazi di stati a grafo si generano più volte gli stessi nodi (o meglio nodi con stesso stato) nella ricerca, anche in assenza di cicli. Visitare stati già visitati fa compiere lavoro inutile. Come evitarlo?
- Ricordando gli stati, ma così aumenta l'occupazione dello spazio.
#### Soluzioni
In ordine crescente di costo ed efficacia:
1. Non tornare nello stato da cui si proviene, si elmina il genitore dai nodi successori (non evita cammini ridondanti).
2. Non creare cammini con cicli, controllando che i successori non siano antenati del nodo corrente (come per la DF).
3. Non espandere nodi con stati già esplorati, ogni nodo visitato deve essere tenuto in memoria per una complessità $O(s)$ dove $s = \#\text{stati possibili}$.

### Ricerca di costo uniforme (UC)
Quando tutti di passi costano uguale, la ricerca BF è ottimale perché espande sempre il nodo non espanso più superficiale. Generalizzando la BF, possiamo trovare un algoritmo che sia ottimale con qualsiasi costo. Invece di espandere il nodo più superficiale, la ricerca a costo uniforme espande il nodo $u$ con il costo di percorso più basso $g(u)$.
Questo viene fatto memorizzando la frontiera come una coda di priorità ordinata per $g$, cioè per costo cammino crescente (in cima i nodi di costo minore).

```ad-note
title: Differenze con la BF
1. Il test obiettivo viene applicato a un nodo quando viene selezionato per l'espansione piuttosto che quando viene generato per la prima volta. Perché il primo nodo obiettivo generato può trovarsi su un percorso non ottimale.
2. Viene aggiunto un test nel caso in cui venga trovato un percorso migliore per un nodo attualmente in frontiera.
```

Ottimalità e completezza garantite purché il costo degli archi sia maggiore di $\varepsilon > 0$. 
- Assunto $C^*$ come costo della soluzione ottima $$\alpha = \underbrace{\left\lfloor \dfrac{C^*}{\varepsilon} \right\rfloor}_{\#\text{mosse al caso pessimo}}$$  e.g attratto ad andare verso tante mosse di costo $\varepsilon$ prima di una che parta più alta ma poi abbia un path a costo totale più basso.
- Complessità: $T(UC) = O(b^{1+\alpha})$.
	- Quando ogni azione ha lo stesso costo UC somiglia a BF ma ha complessità $O(b^{1+d})$, perché il fatto che il testo obiettivo sia posticipato ci fa fare un passo in più per l'ultima frontiera (oltre la profondità del goal).

### Tabellozza di riepilogo

| Criterio      | BF                                     | UC                                                                       | DF       | DL                                            | ID                                     | BIdir       |
| ------------- | -------------------------------------- | ------------------------------------------------------------------------ | -------- | --------------------------------------------- | -------------------------------------- | ----------- |
| **Completa?** | SI                                     | SI $\iff$ tutti archi con costo $c_{ij}\geq\varepsilon > 0$              | NO       | SI$\iff$ problemi con $l$ noto tale che $l>d$ | SI                                     | SI          |
| **Tempo**     | $O(b^d)$                               | $O(b^{1+\alpha})$ con $\alpha = \lfloor \frac{C^*}{\varepsilon} \rfloor$ | $O(b^m)$ | $O(b^l)$                                      | $O(b^d)$                               | $O(b^{d/2}$ |
| **Spazio**    | $O(b^d)$                               | $O(b^{1+\alpha})$ con $\alpha = \lfloor \frac{C^*}{\varepsilon} \rfloor$ | $O(bm)$  | $O(bl)$                                       | $O(bd)$                                | $O(b^{d/2}$ |
| **Ottimale?** | SI $\iff$ archi tutti con costo uguale | SI $\iff$ tutti archi con costo $c_{ij}\geq\varepsilon > 0$              | NO       | NO                                            | SI $\iff$ archi tutti con costo uguale | SI          |
