Table of contents

1. [[#Introduzione|Introduzione]]
	1. [[#Introduzione#Funzioni di valutazione euristica|Funzioni di valutazione euristica]]
	1. [[#Introduzione#Esempi di euristica $h$|Esempi di euristica $h$]]
1. [[#Algoritmo di ricerca Best-First|Algoritmo di ricerca Best-First]]
	1. [[#Algoritmo di ricerca Best-First#Esempio dell'itinerario|Esempio dell'itinerario]]
1. [[#Algoritmo A|Algoritmo A]]
	1. [[#Algoritmo A#Esempio per $f = g  + h$: Il gioco dell'otto|Esempio per $f = g  + h$: Il gioco dell'otto]]
	1. [[#Algoritmo A#Completezza di A|Completezza di A]]
1. [[#Algoritmo A*|Algoritmo A*]]
	1. [[#Algoritmo A*#Formulazione|Formulazione]]
	1. [[#Algoritmo A*#Considerazioni su A*|Considerazioni su A*]]
	1. [[#Algoritmo A*#Ottimalità di A*|Ottimalità di A*]]
		1. [[#Ottimalità di A*#Vantaggi di A*|Vantaggi di A*]]
	1. [[#Algoritmo A*#Conclusioni|Conclusioni]]
1. [[#Costruire le euristiche di A*|Costruire le euristiche di A*]]
	1. [[#Costruire le euristiche di A*#Confronto euristiche ammissibili: Gioco dell'otto|Confronto euristiche ammissibili: Gioco dell'otto]]
	1. [[#Costruire le euristiche di A*#Costo ricerca vs Costo euristica|Costo ricerca vs Costo euristica]]
	1. [[#Costruire le euristiche di A*#Misura del potere euristico|Misura del potere euristico]]
		1. [[#Misura del potere euristico#Capacità di esplorazione|Capacità di esplorazione]]
	1. [[#Costruire le euristiche di A*#Inventare un'euristica|Inventare un'euristica]]
		1. [[#Inventare un'euristica#Rilassamento del problema|Rilassamento del problema]]
		1. [[#Inventare un'euristica#Massimizzazione di euristiche|Massimizzazione di euristiche]]
		1. [[#Inventare un'euristica#Euristiche da sottoproblemi|Euristiche da sottoproblemi]]
		1. [[#Inventare un'euristica#Apprendere dall'esperienza|Apprendere dall'esperienza]]
		1. [[#Inventare un'euristica#Combinazione di euristiche|Combinazione di euristiche]]
1. [[#Algoritmi evoluti basati su A*|Algoritmi evoluti basati su A*]]
	1. [[#Algoritmi evoluti basati su A*#Beam Search|Beam Search]]
	1. [[#Algoritmi evoluti basati su A*#IDA* (A* con approfondimento iterativo)|IDA* (A* con approfondimento iterativo)]]

## Introduzione
La ricerca esaustiva non è praticabile in problemi di complessità esponenziale, possiamo usare la conoscenza del problema unita all'esperienza per riconoscere i cammini più promettenti.
- Usiamo una stima del costo futuro
- Evitando di generare cammini inutili (**pruning**).

La conoscenza euristica aiuta a fare scelte oculate, non evita la ricerca ma la riduce (la facciamo più furba). Consente, in genere, di trovare una buona soluzione in tempi accettabili. Sotto certe condizioni garantisce completezza e ottimalità.

### Funzioni di valutazione euristica
La conoscenza del problema è data tramite una funzione di valutazione $f$, che include $h$ detta **funzione di valutazione euristica**:

$$h:n\to\mathbb{R}$$

La funzione di valutazione $f$ viene interpretata come una stima dei costi, quindi il nodo con la valutazione più bassa viene espanso per primo. La scelta di $f$ determina la strategia di ricerca. La funzione $h$ stima il costo del percorso di costo minimo dallo stato al nodo $u$ a uno stato obiettivo.

n.b: $h(u)$ si applica al nodo $u$, ma, a differenza di $g(n)$, dipende solo dallo stato di quel nodo (`u.stato`).

$$f(u) = g(u) + h(u)$$

cioè, $f$ applicata al nodo è il risultato della somma del costo del cammino con UC e l'applicazione della funzione euristica sul medesimo nodo.

### Esempi di euristica $h$
Vogliamo scegliere $h$ in modo da procedere preferibilmente verso il percorso migliore.
- La città più vicina (in linea d'aria) nel problema dell'itinerario.
- Il numero di caselle fuori posto nel gioco dell'otto.
- Il vantaggio in pezzi nella dama o negli scacchi.

## Algoritmo di ricerca Best-First
La ricerca best-first è un'istanza dell'algoritmo generale TREE-SEARCH o GRAPH-SEARCH in cui un nodo viene selezionato per l'espansione in base a una funzione di valutazione, $f(u)$. 
- La funzione di valutazione è interpretata come una stima del costo, quindi il nodo con la valutazione più bassa viene espanso per primo. 
- L'implementazione della ricerca di grafi best-first è identica a quella della ricerca a costo uniforme, tranne che per l'uso di $f$ al posto di $g$ per ordinare la coda di priorità.

La ricerca greedy best-first cerca di espandere il nodo più vicino all'obiettivo, ritenendo che questo possa portare rapidamente a una soluzione. Pertanto, valuta i nodi utilizzando solo la funzione euristica $h$, ossia $f = h$.
### Esempio dell'itinerario
Vediamo come funziona per i problemi di ricerca del percorso in Romania; usiamo l'euristica della distanza in linea d'aria, che chiameremo $h_{DLD}$ .
Se l'obiettivo è Bucarest, dobbiamo conoscere le distanze in linea d'aria da Bucarest, mostrate qui giù:

| Città          | $h_{DLD}$ |
| -------------- | --------- |
| Bucharest      | 0         |
| Giurgiu        | 77        |
| Urziceni       | 80        |
| Pitesti        | 100       |
| Hirsova        | 151       |
| Craiova        | 160       |
| Eforie         | 161       |
| Fagaras        | 176       |
| Rimnicu-Vilcea | 193       |
| Vaslui         | 199       |
| Iasi           | 226       |
| Neamt          | 234       |
| Mehadia        | 241       |
| Drobeta        | 242       |
| Lugoj          | 244       |
| Sibiu          | 253       |
| Timisoara      | 329       |
| Arad           | 366       |
| Zerind         | 374       |
| Zerind         | 374       |
| Oradea         | 380       | 

Supponiamo di dover partire da Arad.

![[gbf_romania.png]]

- Il primo nodo da espandere da Arad sarà Sibiu, perché è più vicino a Bucarest di Zerind o Timisoara. Il nodo successivo da espandere sarà Fagaras perché è il più vicino. Fagaras a sua volta genera Bucarest, che è l'obiettivo.
- Per questo particolare problema, la ricerca greedy best-first con $h_{DLD}$ trova una soluzione senza mai espandere un nodo che non si trova sul percorso della soluzione; di conseguenza, il suo costo di ricerca è minimo.
- Tuttavia, non è ottimale: il percorso attraverso Sibiu e Fagaras fino a Bucarest è più lungo di 32 chilometri rispetto a quello attraverso Rimnicu-Vilcea e Pitesti.

Questo spiega perché l'algoritmo è chiamato "greedy": a ogni passo cerca di avvicinarsi il più possibile all'obiettivo. Fa la scelta localmente ottima.

## Algoritmo A
Si può dire qualcosa di f per avere garanzie di completezza e ottimalità?

```ad-def
Un algoritmo A è un algoritmo Best First con una funzione di valutazione dello stato del tipo
$$f(u) = g(u) + h(u)\text{, con }h(u)\geq0\text{ e }h(goal)=0$$ 
ricordiamo che $g(u)$ è il costo del cammino percorso per raggiungere $u$ dalla radice e $h(u)$ è una stima del costo per raggiungere da $u$ un nodo goal.
```

Osserveremo come casi particolari dell'algoritmo A:
- $h(u) = 0\implies f(u) = g(u)$ quindi si ha Ricerca uniforme UC
- $g(u) = 0 \implies f(u) = h(u)$ quindi si ha Greedy Best First.

### Esempio per $f = g  + h$: Il gioco dell'otto
In questo caso $g = \#\text{mosse fatte}$ e $h = \#\text{caselle fuori posto}$.
![[problema_gioco8.png]]

$$f(u) = g(u) + h(u) = \#\text{mosse fatte} + \#\text{caselle fuori posto}$$
$$f(Start) = 0 + 7$$
$$f(\textit{goal state}) = \;? + 0$$
e.g dopo $\leftarrow,\downarrow,\uparrow,\rightarrow$ , cioè una mossa a vuoto, lo stato non cambia ma la $g$ si. $f = 4 + 7$

### Completezza di A
```ad-theo
title: Theorem
L'algoritmo A è completo $\iff g(u) \geq \underbrace{d(u)}_{depth} \cdot \varepsilon,\text{ con }\varepsilon>0$ costo minimo arco.
- La condizione sull'$\varepsilon$ è fondamentale, garantisce che non si verifichino situazioni strane del tipo: $$0.9 + 0.09 + 0.009 + \ldots$$ dove sommando numeri via via più piccoli si rischia di non arrivare mai a raggiungere la soglia per trovare la soluzione. Quindi NO somme infinitesime.
```

```ad-proof
title: Proof
- Sia $[u_0,u_1,\ldots,u',\ldots,u_k]$ con $u_k = goal$ un cammino soluzione.
- Sia $u'$ un nodo della frontiera su un cammino soluzione, $u'$ prima o poi sarà espanso.
	- Infatti esistono solo un numero finito di nodi $x$ che possono essere aggiunti alla frontiera con $f(x)\leq f(u')$.
	- È la condizione sulla crescita di $g$ vista sopra, non deve esistere una catena infinita di archi e nodi che possa aggiungere un costo sempre $\leq f(u')$. Prima o poi si supererà il costo di $u'$.
- Quindi, se non si trova una soluzione prima $\implies n'$  verrà espanso e i suoi successori aggiunti alla frontiera. Tra questi anche il suo successore sul cammino soluzione.
- Ragionamento analogo per dimostrare anche che $u_k$ nodo goal sarà selezionato per l'espansione.
```
## Algoritmo A*
È la forma più conosciuta di ricerca best-first. Essa valuta i nodi combinando $g(u)$, il costo per raggiungere il nodo, e $h^*(u)$, il costo per arrivare dal nodo alla meta. Introduciamo la funzione di valutazione ideale (oracolo):
$$f^*(u) = g^*(u) + h^*(u)$$
$$g^*(u) = \text{costo del cammino minimo dalla radice a u}$$
$$h^*(u) = \text{costo del cammino minimo da u al goal}$$
$$f^*(u) = \text{costo del cammino minimo dalla radice al goal, attraverso u}$$
Normalmente $g(u) \geq g^*(u)$ (costo cammino $\geq$ cammino migliore) e $h(u)$ è una stima di $h*(u)$. Si può avere una sottostima, e.g linea d'aria non è come il percorso in km di una strada reale, o una sovrastima.
### Formulazione

```ad-def
$\text{A}^*$ è un algoritmo $\text{A}$ in cui $h$ è una funzione euristica ammissibile.
```

```ad-def
title: Euristica ammissibile (lower-bound condition)
Per ogni stato $u$ vale che $h(u)\leq h^*(u)$, cioè $h$ è una sottostima.
- Un'euristica ammissibile è quella che non sovrastima mai il costo per raggiungere l'obiettivo. Poiché $g(u)$ è il costo effettivo per raggiungere $u$ lungo il percorso corrente e $f(u) = g(u) + h(u)$, abbiamo come conseguenza immediata che $f(u)$ non sovrastima mai il costo reale di una soluzione lungo il percorso corrente che attraversa $n$.
- Le euristiche ammissibili sono per natura ottimiste, perché pensano che il costo della soluzione del problema sia inferiore a quello reale. e.g linea d'aria.
```

```ad-theo
title: Theorem
Gli algoritmo $\text{A}^*$ sono ottimali.
- Ne viene che BF (con passi a costo costante) e UC sono ottimali (quest'ultimo è un caso particolare con $h(u) = 0$).
```

### Considerazioni su A*
1. Rispetto a greedy best-first, la componente $g$ fa sì che si abbandonino cammini che vanno troppo in profondità.
2. $h$ sottostima o sovrastima?
     - Una sottostima può farci compiere del lavoro inutile (tenendo candidati non buoni), però non ci fa perdere il cammino migliore (quello del nodo goal).
     - Una funzione che qualche volta sovrastima può farci perdere la soluzione ottimale, visto che la sovrastima porta a tagliare ramificazioni possibilmente buone.

### Ottimalità di A*
Nel caso di ricerca a/su albero l’uso di un’euristica ammissibile è sufficiente a garantire l’ottimalità di $\text{A}^*$. Per quanto riguarda la ricerca sul grafo, bisogna trovare una proprietà più forte. La **consistenza** (o monotonicità).
- Per evitare di scartare candidati ottimi (non considerando al momento dell'espansione candidati ottimali).
- Cerchiamo quindi condizioni per garantire che il primo espanso sia il migliore.

```ad-def
title: Euristica consistente (o monotona)
$h$ è un'euristica consistente se
- $h(goal) = 0$
- $\forall u.\; h(u) \leq c(u,a,u') + h(u')$ (e.g disugualianza triangolare) dove $u'$ è un successore di $u$.
- Ne viene che $f(u) \leq f(u')$.

n.b se $h$ è consistente $\implies f$ non decresce mai lungo i cammini (monotona).
```

```ad-theo
title: Theorem
Un'euristica monotona è **ammissibile**. 
- Le euristiche monotone garantiscono che la soluzione meno costosa venga trovata per prima e quindi sono ottimali anche nel caso di ricerca su grafo.
	- Non devnono recuperare tra gli antenati nodi con costo minore (gli antenati stanno già negli `esplorati`).
	- Mantengo il controllo sugli esplorati senza cancellare candidati potenzialmente utili, preservando l'ottimalità. `if figlio.Stato not in esplorati and not in frontiera then push(figlio, frontiera)`.
	- Vogliamo mantenere la frontiera pulita (senza stati ripetuti), quindi resta l'if finale  di UC per non perdere l'ottimalità. `if figlio.Stato in frontiera con g più alto then sostituisci quel nodo frontiera con figlio`.
```

```ad-theo
title: Ottimalità di $\text{A}^*$
1. Se $h(u)$ è consistente, i valori di $f(u)$ lungo il cammino sono non decrescenti (monotonia di $f$).
$$\text{Se }h(u) \leq c(u,a,u') + h(u')$$
$$g(u) + h(u) \leq g(u) + c(u, a, u') + h(u')$$
$$\text{visto che }g(u) + c(u, a, u') = g(u')$$
$$\implies g(u) + h(u) \leq g(u') + h(u') \implies f(u) \leq f(u')$$
$$\implies f\textit{ monotona}$$
1. Ogni volta che l'algoritmo seleziona un nodo $u$ per l'espansione, il cammino ottimo a tale nodo è stato trovato:
	- Se così non fosse $\implies$ esisterebbe un altro nodo $m$ della frontiera sul cammino ottimo (verso $n$, ancora da trovare con un cammino ottimo), con $f(m)$ minore (per la monotonia sapendo che $u$ è un successore di $m$); ma ciò è impossibile visto che $m$ sarebbe già stato espanso (si espande prima un nodo con $f$ minore).
3. Quando seleziona il nodo goal il cammino è ottimo ($h=0,f=C^*$).
```

#### Vantaggi di A*
L'algoritmo $\text{A}^*$:
- Espande tutti i nodi con $f(u)<C^*$, dove $C^*$ è il costo ottimo.
- Espande tutti i nodi con $f(u) = C^*$.
- Non espande alcun nodo con $f(u) > C^*$. **[PRUNING]**

Quindi alcuni nodi non verranno considerati per l'espansione (preservando l'ottimalità). Facciamo pruning (con un'opportuna $h$, molto alta ma ammissibile, possiamo evitare l'espansione di molti nodi)

### Conclusioni
L'algoritmo $\text{A}^*$:
- È completo (essendo A completo).
- È ottimale $\iff$ con euristica monotona.
- È ottimamente efficiente (a parità di euristica nessun altro algoritmo espande meno nodi, a meno di rinunciare all'ottimalità).
- Occupazione di memoria pessima a causa della frontiera $O(b^{d+1})$.

## Costruire le euristiche di A*
A parità di ammissibilità, una euristica può essere più efficiente di un’altra nel trovare il cammino soluzione migliore (permette di visitare meno nodi). Questo dipende da quanto informata è l’euristica (cioè dal grado di informazione posseduto).
e.g $h(u) = 0$ euristica non informata (BF o UC); $h(u) = h^*(u)$ massimo delle informazioni (oracolo)

In generale per le euristiche ammissibili: $0\leq h(u) \leq h^*(u)$.

```ad-theo
title: Theorem
Se $h_1 \leq h_2$, i nodi espansi da A* con $h_2$ sono un sottoinsieme di quelli espansi da A* con $h_1$.
- $A^*$ espande tutti i nodi con $f(u) = g(u) + h(u) < C^{*}$ , e sono meno per $h$ maggiori.

Se $h_1 \leq h_2$, A* con $h_2$ è almeno efficiente quanto A* con $h_1$.
n.b: Euristica più informata $\implies$ efficienza (spazio di ricerca ridotto) e più costosa da calcolare.
```

### Confronto euristiche ammissibili: Gioco dell'otto
Abbiamo due euristiche ammissibili per il gioco dell'otto, $h_1$ e $h_2$:

$$h_1:\text{ conta il numero di caselle fuoriposto}$$
$$h_2:\text{ somma delle distanze Manhattan delle caselle fuori posto dalla posizione finale}$$

```ad-help
title: Distanza Manhattan
La distanza tra due punti è la somma del valore assoluto delle differenze delle loro coordinate. È la distanza tra due punti attraverso i quali un taxi si muove in una città utilizzando movimenti orizzontali e verticali della rete.
```

![[gioco8_ex_Astar.png]]

$h_2$ è più informata di $h_1$, infatti $\forall u.\; h_1(u) \leq h_2(u)$, diremo che $h_2$ domina $h_1$.

### Costo ricerca vs Costo euristica
Abbiamo un trade off

![[costoRicVscoCostoEur.png]]

Euristiche poco informate corrispondono a strategie dal costo basso ma dal costo di ricerca molto alto; d'altro canto euristiche molto informate hanno un costo della ricerca bassissimo ma il costo della strategia aumenta, e.g nella ricerca completa ho costo massimo della strategia ma conosco tutto.

### Misura del potere euristico
Possiamo valutare gli algoritmi di ricerca euristica. Introduciamo $b^*$ fattore di diramazione effettivo, siano $N$ il numero di nodi generati e $d$ la profondità della soluzione:

- $b^*$ è il fattore di diramazione di un albero uniforme con $N+1$ nodi. $$ N+1 = b^* + (b^*)^2 + \ldots + (b^*)^d $$ Sperimentalmente una buona euristica ha $b^*\sim 1 (<1.5)$

#### Capacità di esplorazione
Scegliendo un euristica con $b^*=2$, esplorando $100$ nodi arriviamo a profondità 6.
$$d = 6 \;\; N = 100$$
$$d = 12\;\; N=10'000$$

Migliorando di poco l'euristica, $b^* = 1.5$ , miglioriamo non poco anche la profondità a cui arriviamo esplorando 100 nodi.
$$d = 12 \;\; N = 100$$
$$d = 24 \;\; N = 10'000$$

> Migliorando di poco l'euristica si riesce, a parità di nodi espansi, a raggiungere una profondità doppia di esplorazione.

### Inventare un'euristica
Alcune strategie per ottenere euristiche ammissibili:
- Rilassamento del problema
- Massimizzazione di euristiche
- Database di pattern disgiunti
- Combinazione lineare
- Apprendere dall'esperienza

#### Rilassamento del problema
Nel gioco dell'8 posso eseguire una mossa da A verso B se:
1. B è adiacente ad A.
2. B è libera.

$h_1$ e $h_2$ sono calcoli della distanza esatta della soluzione in versioni semplificate del puzzle:
- $h_1$ (nessuna restrizione, né 1 né 2), sono sempre ammessi scambi a piacimento tra caselle (si muove ovunque) $\implies \#\text{caselle fuori posto}$ .
- $h_2$ (solo restrizione 1), sono ammessi spostamenti anche su caselle occupate, purché adiacenti $\implies \text{somma delle distanze Manhattan}$ .

#### Massimizzazione di euristiche
Se si hanno una serie di euristiche ammissibili $h_1,h_2,\ldots,h_k$  senza che nessuna prevalga sull'altra $\implies$ conviene prendere il massimo dei loro valori:
$$h(u) = \max(h_1(u),h_2(u),\ldots,h_k(u))$$
Se $\forall \; i . h_i$ è ammissibile allora anche $h$ lo è, semplicemente $h$ domina tutte le altre.

#### Euristiche da sottoproblemi
Il costo della soluzione ottima al sottoproblema è una sottostima del costo per il problema nel suo complesso.

- Database di pattern: memorizzare ogni istanza del sottoproblema con relativo costo della soluzione. Possiamo utilizzare il database per calcolare $h_{DB}$, estraendo dal database la configurazione corrispondente allo stato completo corrente.

e.g in questa configurazione del gioco dell'otto vogliamo sistemare 1-2-3-4:

![[gioco8_ex2.png]]

- Potremmo poi fare la stessa cosa per altri sottoproblemi: 5-6-7-8, 2-4-6-8,... ottenendo altre euristiche ammissibili.
- Poi prendere il valore massimo (che come visto in precedenza è ammissibile se vengono prese in esame euristiche ammissibili).
	- Tuttavia non possiamo sommarle per ottenere un'euristica ancora più accurata, perché le soluzioni ai sottoproblemi interferiscono (condiviono alcune mosse, e.g se sposto 1-2-3-4 allora sposterò anche 4-5-6-7).
	- In più la somma delle euristiche, in generale, non è ammissile (potremmo sovrastimare avendo avuto aiuti mutui).
- Si deve eliminare il costo delle mosse che contribuiscono all'altro sottoproblema (pattern disgiunti).
- Vogliamo un database di pattern digiunti che consentano di sommare i costi (euristiche additive). e.g solo costo mosse su 1-2-3-4.

#### Apprendere dall'esperienza
Possiamo far girare il programma e raccogliere i dati sotto forma di coppie $\langle \textit{stato}, h^* \rangle$.
- Possiamo così usare i dati per apprendere come predire la $h$, mediante algoritmi di apprendimento induttivo (da istanze note stimiamo $h$ in generale).
- Gli algoritmi di apprendimento si concentrano su caratteristiche salienti dello stato (feature, $x_i$).
	- e.g apprendiamo che da un numero di tasselli fuori posto il costo $\sim 15$.

#### Combinazione di euristiche
Quando diverse caratteristiche influenzano la bontà di uno stato, si può usare una combinazione lineare: $$h(u) = c_1 \cdot x_1(u) + c_2 \cdot x_2 (u) + \ldots + c_k \cdot x_k(u)$$
e.g nel gioco dell'8 $$h(u) = c_1 \cdot \#\text{fuori posto} + c_2 \cdot \#\text{coppie scambiate}$$
negli scacchi $$h(u) = c_1 \cdot \text{vantaggio pezzi} + c_2 \cdot \text{pezzi attaccati} + \ldots$$

- Il peso dei coefficienti $c_i$ può essere aggiustato con l'esperienza, anche qui apprendendo automaticamente da esempi di gioco.
- $h(goal)=0$ ma ammissibilità e consistenza non automatiche.

## Algoritmi evoluti basati su A*
### Beam Search
Nel Best First viene tenuta tutta la frontiera, se l'occupazione di memoria è eccessiva si può ricorrere a questa variante.
- La Beam Search tiene ad ogni passo solo i $k$ nodi più promettenti, dove $k$ è detto beam o ampiezza del raggio dal vulgo italico.
- Non è completa, nemmeno ottima, possibilmente tagliamo la soluzione ottima perché prendiamo un nodo promettente.

### IDA* (A* con approfondimento iterativo)
Combina A* con ID
- Ad ogni iterazione si ricerca in profondità (DF) con un limite (cut-off) dato dal valore della funzione $f$ (e non dalla profondità).
- Il limite $\textit{f-limit}$ viene aumentato ad ogni iterazione, fino a trovare la soluzione.
- Punto critico: di quanto viene aumentato $\textit{f-limit}$.

e.g
![[IDA_ex.png]]

- Se i costi sono fissi $\implies$ basta aumentare di $k$.

```ad-note
title: Incremento
È cruciale la scelta dell'incremento per garantire l'ottimalità:
- Nel caso di costo delle azioni fisso, il limite viene incrementato del costo delle azioni (come abbiamo scritto pocanzi).
- Nel caso di costi delle azioni variabili si potrebbe, ad ogni passo, fissare il limite successivo al valore minimo delle $f$ scartate (in quanto superavano il limite) all'iterazione precedente.
```

```ad-note
title: Analisi di IDA*
È un algoritmo completo e ottimale:
- Se le azioni hanno costo costante $k$ (caso tipico $k=1$) e $\textit{f-limit}$ viene incrementato di $k$.
- Se le azioni hanno costo variabile e l'incremento di $\textit{f-limit}$ è $\leq\varepsilon$ (minimo costo degli archi).
- Se il nuovo $\textit{f-limit}=$ minimo valore $f$ dei nodi generati ed esclusi all'iterazione precedente.

Per quanto riguarda la memoria, visto che è della famiglia DF, occupa $O(bd)$.
```