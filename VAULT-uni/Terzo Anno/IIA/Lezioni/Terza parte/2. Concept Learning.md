Table of contents

1. [[#Premessa|Premessa]]
	1. [[#Premessa#Supervised Learning|Supervised Learning]]
1. [[#Concept Learning|Concept Learning]]
	1. [[#Concept Learning#Apprendimento di funzioni booleane|Apprendimento di funzioni booleane]]
	1. [[#Concept Learning#Regole congiuntive|Regole congiuntive]]
		1. [[#Regole congiuntive#Esempio di Aldo sul tempo, from Mitchell|Esempio di Aldo sul tempo, from Mitchell]]
	1. [[#Concept Learning#Algoritmo Find-S|Algoritmo Find-S]]
	1. [[#Concept Learning#Algoritmo List-Then Eliminate|Algoritmo List-Then Eliminate]]
	1. [[#Concept Learning#Rappresentazione del Version Space|Rappresentazione del Version Space]]
	1. [[#Concept Learning#Algoritmo Candidate Elimination|Algoritmo Candidate Elimination]]
1. [[#Bias induttivo|Bias induttivo]]
	1. [[#Bias induttivo#Learner senza bias|Learner senza bias]]
	1. [[#Bias induttivo#Analisi di learner|Analisi di learner]]

## Premessa
In ML vediamo l'apprendimento come il migliorare, sulla base dell'esperienza, l'esecuzione di un certo task.
### Supervised Learning
Dati degli esempi di training nella forma $\langle input, output \rangle = \langle \vec x, d\rangle$ per una funzione ignota $f$ (di cui conosciamo solo alcuni punti d'esempio), vogliamo trovare una buona approssimazione di $f$ sapendo, grazie al teacher, il target value:
- Per target value intendiamo il valore desiderato di $d$, $t$ o $y$ dato in base a $f(\vec x)$ per etichettare i dati (labelling).
- In questa parte affronteremo il problema della classificazione, dove $f(\vec x)$ restituisce la corretta "classe" per $\vec x$. Ricordiamo che per la classificazione $f(\vec x)$ è un valore discreto.

## Concept Learning
```ad-def
title: Concept Learning
Consiste nel dedurre una funzione booleana da esempi di addestramento positivi e negativi. Sia $X$ lo spazio delle istanze, allora 
$$ c: X \to \{true, false\}\text{ or }\{+,-\} \text{ or }\{0,1\} $$
l'apprendimento di concetti è un particolare caso di classificazione di funzione; come descritto nella formula sopra, la funzione target $c$ restituisce un valore booleanish.

e.g il concetto di gatto è una funzione vera per qualsiasi istanza di gatto e falsa per ogni altro animale.
```

```ad-def
title: Esempio
Sia $D$ il nostro training set, allora definiamo un'esempio come una coppia $$ \langle \vec x, c(\vec x) \rangle = \langle \vec x, d \rangle $$
```

```ad-def
title: Soddisfacibilità
Una funzione $h:X\to\{0,1\}$ soddisfa $\vec x\iff h(\vec x) = 1$ con $\vec x\in X$
```

```ad-def
title: Consistenza
Un'ipotesi $h$ è consistente con:
- Un esempio $\langle \vec x, c(\vec x) \rangle$, con $\vec x\in X$, se $h(\vec x) = c(\vec x)$.
	- cioè $h$ è consistente con un esempio se è uguale al target nella medesima istanza $\vec x$
- $D$ se $h(\vec x) = c(\vec x)$ per ogni esempio di training $\langle \vec x , c(\vec x) \rangle \in D$.
```

### Apprendimento di funzioni booleane
Caso semplice di apprendimento di funzioni booleane. Normalmente abbiamo una funzione logica che, presi zeri e uni, risponde. Il problema del machine learning è l’opposto, dobbiamo trovare la $f$. 

![[ex_boolFunc.png]]![[ex_boolFuncTab.png]]

È un problema mal posto, perché potremo violare l'esistenza, l'unicità o la stabilità della soluzione.

- Ci sono $2^{2^4} = 2^{16} = 65536$ possibili funzioni booleani su quattro feature $x_i$ binarie in ingresso. Non possiamo capire quale sia quella corretta finché non abbiamo visto tutte le possibili coppie ingresso-uscita.
- Dopo 7 esempi, abbiamo comunque $2^9$ possibilità.

In generale abbiamo $$ \# H = 2^{2^n} = 2^{\#\text{istanze}}$$  con $n$ dimensione dell'input.

| $x_1$ | $x_2$ | $x_3$ | $x_4$ | $y$ |
| ----- | ----- | ----- | ----- | --- |
| 0     | 0     | 0     | 0     | ?   |
| 0     | 0     | 0     | 1     | ?   |
| 0     | 0     | 1     | 0     | 0   |
| 0     | 0     | 1     | 1     | 1   |
| 0     | 1     | 0     | 0     | 0   |
| 0     | 1     | 0     | 1     | 0   |
| 0     | 1     | 1     | 0     | 0   |
| 0     | 1     | 1     | 1     | ?   |
| 1     | 0     | 0     | 0     | ?   |
| 1     | 0     | 0     | 1     | 1   |
| 1     | 0     | 1     | 0     | ?   |
| 1     | 0     | 1     | 1     | ?   |
| 1     | 1     | 0     | 0     | 0   |
| 1     | 1     | 0     | 1     | ?   |
| 1     | 1     | 1     | 0     | ?   |
| 1     | 1     | 1     | 1     | ?   |

- Questo modello, noto come **Lookup table model**, risponde solo per i dati che ha già visto, ha una capacità di generalizzazione pessima perché dipende molto dal training set $D$.

```ad-warning
title: Assunzioni 
Da qui in avanti lavoreremo con uno spazio di ipotesi ristretto: iniziamo a scegliere uno spazio di ipotesi $H$ che è considerevolmente più piccolo dello spazio di tutte le funzioni possibili! (bias linguistico).
- Assumeremo un bias, restringeremo il linguaggio con cui lavoreremo. Prenderemo solo regole congiuntive semplice (solo AND e NOT) e poi solo funzioni lineari. I modelli più semplici, rispettivamente, per il discreto e per il continuo.
```

### Regole congiuntive
> Quante regole congiuntive semplici `and` nell'esempio della Tabella 1 (variabili binarie)?
> > 4 inputs: True, 4 singoletti, 6 coppie, 4 triple, 1 quadrupla: 16 ipotesi possibili

In generale: 
- Letterali positivi e.g $h_1 = l_2 \quad h_2 = l_1 \land l_2\quad h_3 = true, \ldots$
	- Le regole congiuntive sono $\# H  = 2^n$, ogni letterale compare o non compare, il che è un valore piccolissimo se pensiamo all'$H$ precedente che era $2^{2^n}$.
- Letterali (anche $\lnot l_i$)
	- $\# H = 3^n + 1$.

#### Esempio di Aldo sul tempo, from Mitchell
> Concetto: "giorni in cui il mio amico Aldo pratica i suoi sport acquatici preferiti".


> Task: prevedere il valore di "Enjoy sport" per un giorno arbitrario
in base ai valori degli altri attributi

![[ex_Aldo1.png]]  ^exAldo

- L'ipotesi $h$ è una congiunzione di vincoli sugli attributi. $$ \langle Sky\quad Temp \quad Humid \quad Wind \quad Water \quad Forecast \rangle $$
- Ogni vincolo può essere:
	- Un valore specifico: e.g $Water = Warm$
	- Un'indifferenza: e.g $Water = \;\;?$
	- Ipotesi nulla, nessun valore consentito: e.g $Water = \emptyset$ (e.g $l_i \land \lnot l_i$)
- Ad esempio consideriamo la seguente funzione $h$ $$ \langle Sunny\quad?\quad Strong \quad ? \quad ? \quad Same \rangle $$ non è un esempio di input, infatti corrisponde alla seguente funzione booleana $$ Sky \land Wind \land Forecast = Sunny \land Strong \land Same $$
- Come conseguenza di quanto scritto fin'ora, possiamo ricavare le seguenti funzioni:
	- La funzione più specifica (sempre falso) $$ \langle \emptyset\quad \emptyset\quad\emptyset\quad\emptyset\quad\emptyset\quad\emptyset \rangle $$
	- La funzione più generale, che non pone vincoli (sempre vero) $$ \langle ?\quad?\quad?\quad?\quad?\quad?\rangle $$ 

```ad-def
title: Prototipo di task di apprendimento di concetti
Siano: 
- $X$ le istanze, nel caso di Aldo i giorni possibili sono descritti dagli attributi (Sky, Temp,...).
- Funzione target $c:\text{EnjoySport }X\to\{0,1\}$
- Spazio delle ipotesi $H$ con $h_i\in H$, congiunzione di (un insieme finito di) letterali $$e.g:\quad h = \langle Sunny\quad ? \quad ? \quad Strong \quad ? \quad Same \rangle$$
- Esempi di training $D$, esempi positivi e negativi della funzione target $$ e.g\quad \langle  \vec x_1,c(\vec x_1) \rangle,\ldots,\langle  \vec x_l,c(\vec x_l) \rangle  \quad (l \text{ esempi})$$

Vogliamo trovare 
- Un ipotesi $h$ in $H$ tale per cui $h(\vec x) = c(\vec x)$ per ogni $\vec x$ in $X$, cioè $$h\in H \mid h(\vec x)=c(\vec x) \; \forall\; \vec x \in X$$
- L'apprendimento diventa una ricerca nello spazio delle ipotesi $H$.
```

```ad-note
title: Ipotesi di apprendimento induttivo
Per questo capitolo faremo la seguente assunzione:
> Qualsiasi ipotesi che approssimi bene la funzione target sugli esempi di addestramento, approssimerà bene anche la funzione target sugli esempi non osservati.

Quindi $$ h(\vec x) = c(\vec x)\;\forall\;\vec x\in D\quad\text e \quad h(\vec x) = c(\vec x)\;\forall\;\vec x\in X$$
```

Cerchiamo di capire meglio che tipo di relazioni intercorrono tra numero di istanze, concetti e ipotesi. Dall'[[#^exAldo|esempio]] capiamo che 

| Attributo | Possibile valore         |
| --------- | ------------------------ |
| Sky       | Sunny or Cloudy or Rainy |
| Temp      | Warm or Cold             |
| Humidity  | Normal or High           |
| Wind      | Strong or Weak           |
| Water     | Warm or Cold             |
| Forecast  | Same or Change           |

la rappresentazione scelta per $H$ determina lo spazio di ricerca
$$\begin{align*}
\#\text{Istanze distinte} &= 3 \cdot 2 \cdot 2 \cdot2 \cdot2 \cdot2 = 96\\\\

\#\text{Concetti distinti} &= 2^{\#\text{istanze}}\\\\

\#\text{Ipotesi distinte sintatticamente(congiunzioni)} &= \underbrace{5}_{sunny/cloudy/rainy/?/\emptyset}\cdot \underbrace{4}_{warm/cold/?/\emptyset} \cdot 4 \cdot4 \cdot4 \cdot4\\\\

\#\text{Ipotesi distinte semanticamente} &= 1 + 4 \cdot 3 \cdot 3 \cdot3 \cdot3 \cdot3 = 973
\end{align*}$$

È chiaro che lo spazio delle ipotesi $H$ ha una dimensione notevole, in alcuni contesti reali pure infinita. Strutturando lo spazio di ricerca si possono rendere più efficienti le ricerche.

```ad-def
title: Ordinamento dal generale allo specifico
Consideriamo due ipotesi $$h_{1}= \langle Sunny\quad ? \quad ? \quad Strong \quad ? \quad ? \rangle \quad h_{2}=\langle Sunny\quad ? \quad? \quad? \quad? \quad?  \rangle$$
cosa possiamo dire riguardo l'insieme delle istanze coperte da $h_1$ e $h_2$?
- $h_2$ impone meno vincoli di $h_1$ e quindi classifica più istanze $x$ come positive (cioè $h(x) = 1$).
------
Siano $h_j$ e $h_k$ delle funzioni a valori booleani definite su $X$, cioè $h_{j},h_{k}:X\to\{0,1\}$. 
Allora $h_j$ più generale o uguale a $h_k$, cioè $h_{j} \geq h_{k}$ se e solo se per ogni istanza $x\in X$ dà positivo con entrambe le funzioni. Cioè $$ \forall\; \vec x \in X .\left[\left( h_{k}(\vec x)= 1 \right)\implies\left( h_{j}(\vec x)= 1 \right) \right] $$

Esempi sul binario non sono comparabili perché la relazione $\geq$ impone un ordine parziale (p.o) sullo spazio delle ipotesi $H$ che viene utilizzato da molti metodi di apprendimento concettuale. Possiamo sfruttare il p.o per organizzare in modo efficace la ricerca in $H$.
```

e.g: consideriamo un esempio dove $h_2$ è più generale di $h_1$ e $h_{3}$, mentre $h_1$ e $h_3$ non sono confrontabili.

![[ex_specificGeneral.png]]

### Algoritmo Find-S
Possiamo sfruttare l'ordinamento parziale per cercare in modo efficiente $h$ consistenti (senza enumerare esplicitamente ogni $h\in H$). 

L'algoritmo Find-S trova l'ipotesi più specifica che si adatta a tutti gli esempi positivi. 
- Inizia con l'ipotesi più specifica e generalizza questa ipotesi ogni volta che non riesce a classificare un dato osservato.
- Passa dall'ipotesi più specifica all'ipotesi più generale.

```ad-def
title: Algoritmo Find-S
1. Inizializza $h$ con l'ipotesi più specifica $$h=\{\emptyset\quad\emptyset\quad\emptyset\quad\emptyset\quad\emptyset\quad\emptyset\}$$
2. Se l'esempio successivo è negativo, l'ipotesi non cambia.
3. Se l'esempio è positivo e ci accorgiamo che la nostra ipotesi iniziale è troppo specifica, allora aggiorniamo la nostra ipotesi attuale a una condizione generale.
	- Per ogni attributo $a_{i}\in h$:
		- Se $a_{i}\in h$ è soddisfatto da $x\implies$ OK
		- $o/w$ rimpiazza $a_i$ con $?$.

e.g: ![[ex_findS.png]]
```

- Find-S produrrà l'ipotesi più specifica all'interno di $H$ che sia consistente con gli esempi positivi di training.
- L'ipotesi di output $h$ sarà anche consistente con gli esempi negativi, a condizione che il target sia contenuto in $H$ (la funzione target nel caso precedente è un AND di letterali, in generale $h$ non può essere più generale di $c$).

```ad-warning
title: Perché Find-S fa cacare?
- Non è in grado di stabilire se ha trovato l'unica ipotesi consistente con gli esempi di training.
- Non c'è tolleranza al rumore, non capisce quando gli esempi di training sono incoerenti perché ignora i negativi.
```

Noi vorremmo fornire una descrizione dell'insieme di tutti gli $h$ consistenti con $D$. Possiamo farlo senza enumerarli tutti $$\text{Consistent}(h,D) := \forall\;\langle \vec x,c(\vec x) \rangle \in D. h(\vec x) = c(\vec x)$$

```ad-def
title: Version spaces
Lo spazio delle versioni $VS_{HD}$ rispetto allo spazio delle ipotesi $H$ e l'insieme di training $D$, è il sottoinsieme delle ipotesi di $H$ consistenti con tutti gli esempi di training.
$$VS_{HD}= \{ h\in H \mid \text{Consistent}(h,D) \}$$
- Per emettere una descrizione di tutte le ipotesi consistenti col l'insieme di training $D$,  non abbiamo la necessità di enumerare tutte le ipotesi.
```

^ceea66

### Algoritmo List-Then Eliminate 
L'algoritmo List-Then-Eliminate è un altro algoritmo di apprendimento. Questo algoritmo inizia con uno Spazio delle versioni completo (un elenco contenente tutte le ipotesi in H). Poi, per ogni esempio di addestramento, si rimuovono tutte le ipotesi (dallo spazio delle versioni) che non concordano con l'esempio di addestramento.

- Fa veramente cacare come algoritmo:
	- Non sfruttiamo il partial order
	- Enumeriamo tutte le ipotesi $h$ in $H$.

### Rappresentazione del Version Space
Non dobbiamo portarci dietro tutte le ipotesi

![[repr_VersionSpace.png]]

solo la più specifica $S$ (quella trovata con Find-S) e la più generale $G$.

```ad-def

- Il limite generale, $G$, del version space $VS_{HD}$ è l'insieme dei membri massimamente generali (di $H$ consistente con $D$).
- Il limite specifico, $S$, del version space $VS_{HD}$ è l'insieme dei membri massimamente specifici (di $H$ consistente con $D$).
```

```ad-theo
title: Theorem
Ogni membro del version space si trova fra $G$ e $S$ $$ VS_{HD} = \{ h \in H \mid (\exists\; s \in S)\;(\exists\; g \in G)\;(g \geq h \geq s) \} $$ 
```
Possiamo effettuare una ricerca completa di ipotesi coerenti utilizzando i due confini $S$ e $G$ per il version space.

### Algoritmo Candidate Elimination
Siano $G$ l'ipotesi più generale di $H$ e $S$ l'ipotesi più specifica di $H$.
Per ogni esempio di training $d = \langle x , c(x) \rangle$:
- Se $d$ è un esempio positivo
	- Rimuovi da $G$ qualunque ipotesi sia inconsistente con $d$
	- Per ogni ipotesi $s\in S$ che non è consistente con $d$  (dobbiamo generalizzare $S$).
		- Rimuovi $s$ da $S$
		- Aggiungi ad $S$ tutte le generalizzazioni minime $h$ di $s$ tali che
			- $h$ sia consistente con $d$
			- alcuni membri di $G$ sono più generali di $h$ (alcuni di $G$ per il partial order).
		- Elimina da $S$ qualsiasi ipotesi che sia più generale di un'altra ipotesi in $S$.
- Se $d$ è un esempio negativo
	- Rimuovi da $S$ qualunque ipotesi sia inconsistente ($h$ è 1) con $d$
	- Per ogni ipotesi $g \in G$ che non è consistente con $d$ (dobbiamo specializzare $G$).
		- Rimuovi $g$ da $G$
		- Aggiungi a $G$ tutte le specializzazioni minime $h$ di $g$ tali che
			- $h$ sia consistente con $d$
			- alcuni membri di $S$ sono più specifici di $h$
		- Rimuovi da $G$ qualsiasi ipotesi che sia meno generale di un'altra ipotesi in $G$.

e.g: 
$$ \begin{align*}
S &= \{(\emptyset,\emptyset,\emptyset,\emptyset,\emptyset,\emptyset)\}\\
G &= \{(?,?,?,?,?,?)\}
\end{align*}
$$

| it. | $x_i$                                   | S                                          | G                                                             |
| --- | --------------------------------------- | ------------------------------------------ | ------------------------------------------------------------- |
| 1   | $(Sunny,Warm,Normal,Strong,Warm,Same)+$ | $\{(Sunny,Warm,Normal,Strong,Warm,Same)\}$ | //                                                            |
| 2   | $(Sunny,Warm,High,Strong,Warm,Same)+$   | $\{(Sunny,Warm,?,Strong,Warm,Same)\}$      | //                                                            |
| 3   | $(Rainy,Cold,High,Strong,Warm,Change)-$ | //                                         | $\{ (Sunny,?,?,?,?,?), (?,Warm,?,?,?,?), (?,?,?,?,?,Same) \}$ |
| 4   | $(Sunny,Warm,High,Strong,Cool,Change)+$ | $\{ \langle Sunny,Warm,?,Strong,?,? \rangle \}$            | $\{ (Sunny,?,?,?,?,?), (?,Warm,?,?,?,?) \}$                                                            |

$x_4$ non è più consistente con $G$ (non dà $+$ su $x_4$)

```ad-note
title: Classificare nuovi dati
![[classificare_nuoviDati.png]]

Per $x_7$ non possiamo rispondere.
```

^45276d

## Bias induttivo
Il nostro spazio delle ipotesi non è in grado di rappresentare la funzione target semplice e disgiuntiva: $$(Sky=Sunny)\lor (Sky=Cloudy)$$ Osserviamo candidate elimination su $$ \begin{align*}
x_{1} &= \langle Sunny\quad Warm\quad Normal\quad Strong\quad Cool\quad Change \rangle + \\
x_{2} &= \langle Cloudy\quad Warm\quad Normal\quad Strong\quad Cool\quad Change \rangle +
\end{align*} $$
$$ S: \{ \langle ?\quad Warm\quad Normal\quad Strong\quad Cool\quad Change \rangle \} $$
$$ x_{3} = \langle  Rainy\quad Warm\quad Normal\quad Strong\quad Cool\quad Change \rangle - $$
$$ S: \{\} $$
Non si può trovare un ipotesi consistente con $x_3$ perché non si trova una regola con AND (solo OR può salvarci ma non si può fare, abbiamo solo regole congiuntive).
- Assumiamo che lo spazio delle ipotesi $H$ contenga la funzione target $c$. Cioè $c$ può essere descritto da una congiunzione di letterali.

### Learner senza bias
Prendere un $H$ più espressiva sarebbe una possibile soluzione, ad esempio $H$ con disgiunzione, negazione e congiunzione; così sicuramente $H$ comprende la funzione target.
- Ma il *downside* di questo approccio è che deterioro la generalizzazione.
- Assumendo $x_1,x_2,x_3$ esempi positivi e $x_4,x_5$ esempi negativi, chi sono $S$ e $G$? $$ S:\{ (x_{1} \lor x_{2} \lor x_{3}) \} \quad G:\{ \lnot (x_{4}\lor x_5) \}$$
	- Gli unici esempi classificati in modo univoco sono gli esempi di training stessi ($H$ può rappresentarli). 
	- Quindi per apprendere la funzione target si dovrebbe presentare ogni singola istanza di $X$ come esempio di training.
		- Non possiamo inferire nessuna funzione, faremo solo una grande look up table (che schifo).

```ad-def
title: No bias ergo no generalizzazione
Un learner senza bias non è in grado di generalizzare. 
- Ogni istanza non osservata sarà classificata come positiva da metà delle ipotesi in version space e negativa dall'altra metà
	- Finisce sempre nella zona grigia tra pari positivi e pari negativi [[#^45276d|e.g]]

Infatti per ogni $h$ consistente con i test $x_i$, esiste una $h'$ identica ad $h$ tranne per $h'(x_{i})<> h(x_i)$ (uguale ovunque tranne in $x_i$), $h\in VS \implies h'\in VS$. $h$ e $h'$ sono identici su $D$ (il training set). 
```

Un learner che non fa ipotesi preliminari sull'identità della funzione target non ha una base razionale per classificare le istanze non viste (serve il Bias per questo). 
- Il bias non è solo assunto per efficienza, è necessario per generalizzare.
- Tuttavia, non ci dice (quantifica) quale sia la soluzione migliore per la generalizzazione.

```ad-def
title: Bias induttivo
Consideriamo:
- $L$ algoritmo di apprendimento di concetti.
- $X$ istanze, funzione target $c$.
- Esempi di training $\langle  x,c(x) \rangle \in D_c$
- Sia $L(x_{i},D_{c})$ la classificazione assegnata all'istanza $x_i$ da $L$ dopo il training su $D_c$.

Definiamo con bias induttivo di $L$ un qualsiasi insieme minimo di asserzioni $B$ tale che per qualsiasi funzione target $c$ e corrispondenti esempi di training in $D_c$ $$ (\forall\; x_{i} \in X) \;[ B \land D_{c} \land x_{i}]\vdash L(x_{i}, D_c) $$ è l'insieme di assunzioni che il classificatore usa per predire l'output dati gli input che esso non ha ancora incontrato.
```

```ad-def
title: Bias induttivo (by Chat-GPT)
Il bias induttivo si riferisce alle ipotesi o alle preferenze intrinseche che un algoritmo o un modello ha incorporato durante il suo sviluppo. Questi *"pregiudizi"* sono necessari affinché i modelli di apprendimento automatico generalizzino da un insieme limitato di dati di addestramento a nuovi dati non visti.

Il bias induttivo può assumere diverse forme, a seconda del tipo di algoritmo di apprendimento e del problema che sta cercando di risolvere. Per esempio, nell'apprendimento supervisionato, un bias induttivo può comportare l'assunzione che la relazione tra input e output sia lineare, o che certe caratteristiche siano più importanti di altre.

Il bias induttivo può essere sia vantaggioso che problematico. Da un lato, un bias ben progettato può aiutare un modello ad apprendere in modo più efficiente e accurato. D'altro canto, se il bias è troppo forte o inappropriato per il problema in questione, può portare a prestazioni scadenti e persino a risultati dannosi.
```

### Analisi di learner
- **Apprendimento "meccanico" (lookup table)**. Memorizza gli esempi, classifica $x$ se e solo se corrisponde a un esempio precedentemente osservato.
	- No bias induttivo $\implies$ nessuna generalizzazione.
- **Algoritmo version space candidate elimination**. 
	- Con bias, lo spazio delle ipotesi contiene la funzione target (coniugazione di attributi) $\# H= 973$  contro 1028.
- **Algoritmo Find-S**. 
	- Con bias, lo spazio delle ipotesi contiene la funzione target e tutte le istanze sono istanze negative, a meno che il contrario non sia implicato dalle altre conoscenze (viste come esempi positivi).
	- In soldoni, abbiamo un bias linguistico dovuto all'AND sui letterali più un bias di ricerca dovuto alla preferenza dell'ipotesi più specifica.