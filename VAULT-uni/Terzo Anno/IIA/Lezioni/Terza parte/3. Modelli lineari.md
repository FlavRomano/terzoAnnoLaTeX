Table of contents

1. [[#Regressione|Regressione]]
	1. [[#Regressione#Regressione lineare univariata|Regressione lineare univariata]]
	1. [[#Regressione#Least mean square|Least mean square]]
	1. [[#Regressione#Discesa del gradiente (ricerca locale)|Discesa del gradiente (ricerca locale)]]
		1. [[#Discesa del gradiente (ricerca locale)#Conclusioni sul gradiente discendente|Conclusioni sul gradiente discendente]]
	1. [[#Regressione#Estensione su $l$ patterns|Estensione su $l$ patterns]]
	1. [[#Regressione#Input multidimensionali|Input multidimensionali]]
	1. [[#Regressione#Algoritmo del gradiente discendente|Algoritmo del gradiente discendente]]
	1. [[#Regressione#Limitazioni della regressione lineare|Limitazioni della regressione lineare]]
1. [[#Linear Basis expansion|Linear Basis expansion]]
1. [[#Verso la regolarizzazione|Verso la regolarizzazione]]
	1. [[#Verso la regolarizzazione#Regolarizzazione di Tikhonov (Ridge Regression)|Regolarizzazione di Tikhonov (Ridge Regression)]]
	1. [[#Verso la regolarizzazione#Limitazioni delle Fixed Basis Function|Limitazioni delle Fixed Basis Function]]
1. [[#Classificazione|Classificazione]]
	1. [[#Classificazione#Classificazione per confini decisionali lineari|Classificazione per confini decisionali lineari]]
		1. [[#Classificazione per confini decisionali lineari#Esempio spam|Esempio spam]]
	1. [[#Classificazione#Il problema dell'apprendimento per classificatori lineari|Il problema dell'apprendimento per classificatori lineari]]
		1. [[#Il problema dell'apprendimento per classificatori lineari#Congiunzioni con i modelli lineari|Congiunzioni con i modelli lineari]]


```ad-note
title: Recap ingredienti
- **Dati** di allenamento
- **Spazio delle ipotesi** $H$
	- costituisce l‚Äôinsieme delle funzioni che possono essere realizzate dal sistema di   apprendimento;
	- si assume che la funzione da apprendere $f$ possa essere rappresentata da una ipotesi $h$ in $H$ (selezione di $h$ attraverso i dati di apprendimento)
	- o che almeno una ipotesi $h$ in $H$ sia simile a $f$ (approssimazione);
- **Algoritmo di apprendimento** *aka* Algoritmo di ricerca nello spazio delle ipotesi. e.g: adattamento dei parametri liberi del modello al task.

n.b: $H$ non pu√≤ coincidere con l'insieme di tutte le funzioni possibili e la ricerca essere esaustiva (Bias induttivo)
```

## Regressione
e.g Predire la temperatura di domani.

√à possibile fare learning con modelli semplici come le equazioni lineari.

La regressione √® il processo di stima di una funzione a valori reali sulla base di un insieme finito di campioni rumorosi.

e.g: Nota la coppia $$\langle x, f(x) + rumore \rangle$$ vogliamo trovare la $f$ per i dati della seguente tabella:

![[regression1.png]]

Vogliamo trovare le componenti del polinomio, cio√® $w_1$ e $w_0$, in maniera sistematica sulla base dei nostri dati. La retta $h(x) = 2x$ pu√≤ essere una buona ipotesi.

### Regressione lineare univariata
√à un caso semplice di regressione lineare. Si parte con un input $x$ e un output $y$. 
Assumeremo un modello $h_w(x)$ espresso da $$out = h(x) = w_{1}x + w_{0}$$
dove $w$ sono coefficienti a valori reali o **pesi**.

- Vogliamo fare fitting dei dati trovando la linea retta che passa da quest'ultimi.

```ad-example
title: Esempio di task e modello
Vogliamo trovare $h$ (modello lineare) che meglio si adatti ai dati (l'insieme dei dati $x$ e $y$ osservati).

![[aima_regressionEx.png]]

- Assumendo che una data variabile $y$ sia correlata, linearmente, a un'altra variabile $x$ (o da variabili $x_i$) attraverso $$y = w_{1}x + w_{0} + noise$$ dove $w_i$ sono parametri liberi e il rumore √® l'errore nella misurazione del target (errore con distribuzione normale).
- Costruiamo un modello, trovando i valori di $w$, per prevedere/stimare il prezzo $y$ dei punti per altri valori $x$ (non osservati). Quindi fare una **previsione**.

![[aima_regressionEx2.png]]
```

### Least mean square
In soldoni, dobbiamo trovare i valori dei parametri $w_i$ ($w_1$ e $w_0$ nel caso univariato) al fine di minimizzare l'errore di output del modello, fare quindi buon fitting.

Il problema √® che abbiamo uno spazio delle ipotesi infinito (valori continui di $w$), ci vengono in aiuto le scoperte di fine '700 di *Gauss* e *Legendre*.
- Definiamo una funzione di Loss (perdita o errore) e utilizziamo il **Least Mean Square**.
- Vogliamo imparare a trovare $w$ in modo da minimizzare l'errore (perdita empirica) per consentire miglio adattamento sui dati (insieme di training).

```ad-def
title: Least Mean Square
Dato un set di $l$ esempi di training $(x_{p}, y_{p})$ $$p = 1\ldots l$$ vogliamo trovare $h_{w}(x)$ nella forma $w_{1}x + w_{0}$ (quindi i valori di $w$) in modo tale da minimizzare la perdita attesa (expected loss) sui valori di training.

n.b: l'expected loss √® l'errore medio sui valori di training.

- Per la perdita utilizziamo il quadrato degli errori.
- Vogliamo trovare $w$ per minimizzare la somma dei quadrati residua 

$$Loss(h_{w}) = E[w] = \sum\limits_{p=1}^{l}(y_{p} - h_{w}(x_{p}))^{2} = \sum\limits_{p=1}^{l} (y_{p} - (w_{1}x_{p} + w_{0}))^2$$ dove $x_{p}$ √® il $p$-esimo input, $y_{p}$ √® il $p$-esimo output per $p$.
```

Un punto di minimo locale √® un punto stazionario, *ergo* l√¨ il gradiente √® nullo. Cercando i punti dove il gradiente √® nullo, troviamo il minimo della funzione che stiamo cercando. $$\frac{\partial}{\partial w_{i}} E[w] = 0 \quad i = 1,\ldots,dim\_input + 1$$
- Per la regressione lineare semplice (due parametri liberi) $$\frac{\partial}{\partial w_{0}}E[x] = 0\quad \frac{\partial}{\partial w_{1}}E[x] = 0$$ visto che la funzione √® convessa, non abbiamo minimi locali. $$w_{1}= \frac{\text{Cov(x,y)}}{\text{Var}(x)} \quad w_{0}=\overline y - w_{1}\overline x,\quad \text{con}\quad \overline y = \frac{1}{l}\sum\limits_{p\to l} y_{p}\quad \overline x = \frac{1}{l}\sum\limits_{p\to l}x_{p}$$ 

e.g: Calcolare il gradiente per ogni pattern $p$ $$\begin{align*}
\frac{\partial}{\partial w_{i}}E[x] &= \frac{\partial}{\partial w_{i}} (y - h_{w}(x))^{2} \\
&= 2\left(y - h_{w}(x)\right)\cdot \frac{\partial}{\partial w_{i}} (y - h_{w}(x))\\
\end{align*}$$ quindi $\dfrac{\partial}{\partial w_{0}} =-2(y-h_{w}(x))$ , $\dfrac{\partial}{\partial w_{1}} =-2(y-h_{w}(x)) \cdot x$

[[4. Ricerca locale#Ricerca locale in spazi continui| Repetita sugli spazi continui e il gradiente]]

### Discesa del gradiente (ricerca locale)
Ci√≤ che abbiamo detto fin'ora d√† un hint, costruire un algoritmo iterativo basato su $\dfrac{\partial}{\partial w_{i}} E[w]$

- Il gradiente fornisce la direzione di ascesa, *ergo* possiamo muoverci verso il minimo con una **discesa del gradiente**. Indicheremo con $\Delta w = -\nabla w = -\text{gradiente di }E[w]$ 

Parliamo di ricerca locale, iniziamo con un vettore di pesi iniziale. Verr√† modificato iterativamente per diminuire fino a minimizzare la funzione di errore (discesa rapida).

```ad-def
title: Learning rate (tasso di apprendimento)
Il tasso di apprendimento $\eta$ √® un iperparametro (noi abbiamo detto semplicemente "costante") che controlla i pesi del modello rispetto alla discesa del gradiente. $$w_{new} = w + \eta \cdot \Delta w$$ Definisce la velocit√† con cui il modello aggiorna i concetti appresi.
```

```ad-theo
title: Delta rule (error correction)
$\Delta w$ cresce rispetto alla distanza tra $y$ e $h$, la delta rule √® una regola che cambia i pesi $w$ proporzionalmente all'errore.
1. $$\text{target }y - \text{output }h = \text{errore} = 0 \implies \textbf{OK}, \text{ nessuna correzione}$$
2. $$\text{output} > \text{target} \implies y-h < 0 $$ in questo caso l'output √® troppo alto, dobbiamo abbassare la retta per avvicinarci al target.
	- Allora $\Delta w_{0}$ √® negativo, quindi dobbiamo ridurre $w_{0}$.
	- Se $(\text{input } x>0)$ allora $\Delta w_1$ √® negativo, quindi dobbiamo ridurre $w_1$
		- Altrimenti avremmo dovuto incrementare $w_1$.

Impariamo dai nostri errori ü•∫.
```

#### Conclusioni sul gradiente discendente
Il metodo di discesa del gradiente √® un approccio di ricerca locale semplice ed efficace per la soluzione dei Least Mean Squares, inoltre:
- Ci permette di cercare in uno spazio di ipotesi infinito.
- Pu√≤ essere sempre facilmente applicato  per $H$ continuo e loss differenziabile.
- Non √® il pi√π efficiente, si √® migliorato con gli anni (Metodi di Newton, gradiente coniugato).

### Estensione su $l$ patterns
Per $l$ patterns $(x_{p},y_{p})$ $$ \begin{align*}
\Delta w_{0} &= - \frac{\partial}{\partial w_{0}}E[w] = 2 \sum\limits_{p=1}^{l}(y_{p}- h_{w}(x_{p})) \\\\
\Delta w_{1} &= - \frac{\partial}{\partial w_{1}}E[w] = 2 \sum\limits_{p=1}^{l}(y_{p}- h_{w}(x_{p}))\cdot x_{p}
\end{align*} $$ dove $x_p$ √® il $p$-esimo input, $y_{p}$ √® il $p$-esimo output per $p$, $w$ parametro libero e $l$ il numero di esempi.

```ad-question
title: Quando aggiornare i pesi
Quando conviene aggiornare i pesi $w_{0}$ e $w_{1}$? Dopo un passo grande o dopo tanti piccoli passi?

![[aggiornamento_pesi.png]]

- Possiamo aggiornare $w$ dopo un *epoca* di $l$ esempi. Questa prassi √® nota come **Batch algorithm**. Nella figura √® in blu.
- Oppure aggiornare $w$ dopo ogni pattern $p$. Questo √® noto come **On-line algorithm** (discesa stocastica del gradiente). Nella figura √® in viola e verde.
	- Abbiamo un coefficiente di apprendimento $\eta$ minore ma pu√≤ essere il pi√π veloce.
```

### Input multidimensionali
Come notazione assumiamo $l = \#dati$ e $n = \#variabili$, avere come input pattern un vettore √® un caso molto comune: $$x = \begin{pmatrix}x_{1},x_{2},\ldots ,x_{n}\end{pmatrix}$$

e.g: 
1. Valutare (come punteggio) lo stato della scacchiera in una partita di dama in base al numero di pezzi bianchi/neri/re/catturati nel turno successivo: abbiamo 6 variabili. $w$ pesa tali caratteristiche della "scacchiera".
2. Valutare il prezzo della casa considerando anche il numero di stanze, l'et√† della casa, il rango del quartiere, ecc...

$X$ √® una matrice $l \times n$, con $l$ righe ed $n$ colonne

$$
\begin{array}{c c} 
& \begin{array}{c c c c} x_{1}\;\; & x_{2} & x_{i}\; & x_{n} \\ \end{array} \\
\begin{array}{c c c c}\text{Pat 1}\\ \ldots\\ \text{Pat }p \\ \ldots\end{array} &
\left(
\begin{array}{c c c c}
x_{1,1} & x_{1,2} &  & x_{1,n} \\
 \\
x_{p,1} & x_{p,2} & x_{p,i} & x_{p,n} \\
\\
\end{array}
\right)
\end{array}
$$

| Pattern  | $x_{1}$   | $x_{2}$   | $x_{i}$   | $x_{n}$   |
| -------- | --------- | --------- | --------- | --------- |
| Pat 1    | $x_{1,1}$ | $x_{1,2}$ |           | $x_{1,n}$ |
| $\ldots$ |           |           |           |           |
| Pat $p$  | $x_{p,1}$ | $x_{p,2}$ | $x_{p,i}$ | $x_{p,n}$ |
| $\ldots$ |           |           |           |           |

Ogni riga, generica $x$, pu√≤ essere un esempio (di input), pattern, instanza e cos√¨ via...

- Abbiamo $p = 1\ldots l$ e $i = 1\ldots n$
- Per il target tipicamente usiamo $y_{p}$ (stessa con $d$ oppure $t$).

$$w^{T}x + w_{0} = w_{0} + w_{1}x_{1}+ w_{2}x_{2}+\ldots+w_{n}x_{n} = w_{0} + \sum\limits_{i=1}^{n} w_{i}x_{i}$$ spesso la $T$ in $w^T$ viene omessa.

- $w_0$ √® nota come intercetta, *threshold*, *offset* o *bias* (non √® il bias induttivo).
- Spesso √® utile fissare il primo componente $x_{0} = 1$ per riscriverla cos√¨: $$\begin{align*}
w^{T}x &= x^{T}w\quad\text{(prodotto scalare)}\\
x^{T} &= \begin{pmatrix}1 & x_{1}& x_{2} & \ldots &x_{n} \end{pmatrix}\\
w^{T} &= \begin{pmatrix}w_{0}& w_{1}& w_{2} &\ldots &w_{n}\end{pmatrix}
\end{align*}$$

```ad-note
title: Dal punto di vista geometrico
Per 2 variabili: $$x^{T}w = w^{T}x = w_{0}+ w_{1}x_{1}+ w_{2}x_{2}$$

![[iperpiano.png]]

Per $n$ dimensioni: $$w^{T}= \begin{pmatrix}w_{0}, w_{1}, w_{2},\ldots, w_{n}\end{pmatrix}$$ quindi $$h(x_{p}) = x_{p}^{T}w = \sum\limits_{i=0}^{n}x_{p,i}w_{i}$$
```
Dato un insieme di $l$ patterns di training $(x_{p}, y_{p})$. Vogliamo trovare il vettore dei pesi $w$ tale che minimizzi la loss attesa sui dati di training $$E[w] = \sum\limits_{p=1}^{l}(y_{p}- x_{p}^{T}w)^{2} = \lvert \rvert y - X w\lvert\rvert^2$$
Per quanto riguarda il vettore gradiente: $$\Delta w = -\frac{\partial}{\partial w} E[w] = \begin{pmatrix} -\dfrac{\partial}{\partial w_{1}} E[w] \\  \vdots \\ -\dfrac{\partial}{\partial w_{n}} E[w]\end{pmatrix} = \begin{pmatrix} -\Delta w_1 \\  \vdots \\ -\Delta w_n\end{pmatrix}$$

### Algoritmo del gradiente discendente
1. Parti con un vettore dei pesi $w_{initial}$ piccolo e fissa un $\eta \in (0,1)$.
2. Per ogni $w_{i}$ calcola il gradiente di $E[w]$, cio√® $\Delta w = - \dfrac{\partial}{\partial w} E[w]$
3. Per ogni $w_{i}$ calcola $w_{new}= w + \eta \cdot \Delta w$ (regola di apprendimento).
4. GOTO 2 **until** $\Delta w$ converge o $E[w]$ √® sufficientemente piccolo.

- Versione batch, aggiorna $w$ dopo un'epoca di $l$ dati.
- Versione on-line, aggiorna $w$ dopo ogni pattern $p$.
- $\eta \to 0$ garantisce convergenza.

### Limitazioni della regressione lineare
La regressione non √® esente di problemi. Il termine *lineare* non si riferisce alla linea retta, ma al modo in cui i coefficienti di regressione $w$ si presentano nell'equazione di regressione. $$h_{w}(x) = w_{1}x + w_{0} $$  quindi possiamo utilizzare anche input trasformati $x, x^{2}, x^{3},\ldots$  con relazioni non lineari tra input e output. Continuando a utilizzare il metodo dei minimi quadrati. $$h_{w}(x) = w_{0}+w_{1}x+w_{2}x^{2}+\ldots+w_{M}x^{M} = \sum\limits_{j=0}^{M} w_{j}x^{j} \quad \textit{(regressione polinomiale)}$$ posso fare fitting di una funzione lineare nei parametri $w$, nei minimi quadrati lineari non √® necessario che la funzione sia lineare nell'argomento.

## Linear Basis expansion
La LBE √® una tecnica utilizzata nell'IA e nell'apprendimento automatico per trasformare i dati di input in uno spazio di dimensioni superiori, al fine di catturare meglio le relazioni e i modelli non lineari nei dati.
Prevede che i dati di ingresso originali vengano trasformati utilizzando un insieme di funzioni base che sono combinazioni lineari delle feature di ingresso originali. Queste funzioni base possono essere semplici funzioni polinomiali, come le funzioni quadratiche o cubiche. 
$$h_{w}(x) = \sum\limits_{k=0}^{K}w_{k}\phi_{k}(x)$$ 
- Aumentiamo il vettore input con variabili aggiuntive che sono trasformazioni di $x$ secondo una funzione $\phi$. e.g $\phi(x) = x_{j}^{2}$, $\phi(x) = x_{j}x_{i}$
- Ampliamo il numero di parametri liberi, creando ulteriori combinazioni. $K > n$.
- Possiamo usare lo stesso algoritmo di apprendimento di prima.

Questo metodo √® molto espressivo ed √® capace di modellare relazioni complicate (a differenza della regressione lineare), tuttavia √® difficile controllare la complessit√† del modello con funzioni con tante basi (fa buon fitting ma generalizza molto male). Sia $M$ il grado del polinomio.

$$h_{w}(x) = w_{0}+w_{1}x+w_{2}x^{2}+\ldots+w_{M}x^{M} = \sum\limits_{j=0}^{M} w_{j}x^{j} \quad \textit{(regressione polinomiale)}$$ 

![[ex_lbe.png]]

![[ex_lbe2.png]]

![[ex_lbe3.png]]

Quest'ultimo polinomio ci fa osservare una cosa, nonostante l'errore quadratico medio $E[w]$ sia 0 sui dati di training, abbiamo fatto fitting anche del rumore (modello troppo complesso) e la rappresentazione si √® scacata (overfitting per la troppa aderenza ai dati).
- Si vuole scegliere la regolarizzazione per bilanciare i due casi attraverso il controllo della complessit√† del modello (vista come **flessibilit√†**, polinomio di grado alto √® pi√π COMPLESSO di un polinomio di grado basso).

## Verso la regolarizzazione
La regolarizzazione pu√≤ controllare l'overfitting, penalizzando le funzioni complesse (polinomi di grado alto) con elevati valori dei pesi $w$ (restringendo i coefficienti) o il numero di parametri liberi. Mantenendo la flessibilit√† dello spazio delle ipotesi.
> "La spiegazione pi√π semplice √® probabilmente quella pi√π corretta".

> "Preferire l'ipotesi pi√π semplice che si adatta ai dati".

### Regolarizzazione di Tikhonov (Ridge Regression)
La regolarizzazione di Tikhonov, nota anche come regressione ridge, √® un metodo di regressione lineare utilizzato per affrontare il problema dell'overfitting, in cui il modello si adatta troppo bene ai dati di addestramento e si generalizza male a nuovi dati.

√à possibile aggiungere vincoli alla somma dei valori di $\lvert w_{j}\rvert$ favorendo modelli *sparsi*, e.g con meno termini dovuti a pesi $w_{j}\to0$ (quindi un modello meno complesso).

Nella regolarizzazione di Tikhonov, alla funzione di loss del modello di regressione lineare viene aggiunto un termine di penalit√† che scoraggia il modello dall'adattarsi troppo strettamente ai dati di addestramento. Il termine di penalit√† √® la norma 2 al quadrato dei coefficienti del modello, moltiplicata per un iperparametro lambda, che controlla la forza della penalit√†.

$$\text{Loss}(h_{w})=\sum\limits_{p=1}^{l}(y_{p}- h_{w}(x_{p}))^{2} + \underbrace{\lambda \lvert\lvert w \rvert\rvert^2}_{}$$

- L'iperparametro lambda controlla il compromesso tra il buon adattamento ai dati di addestramento e la riduzione dei coefficienti.
- Aggiungendo il termine di penalit√†, la regolarizzazione di Tikhonov riduce i coefficienti a zero, riducendo la loro entit√† e la varianza del modello. 
- Il risultato √® un modello pi√π omogeneo, che ha meno probabilit√† di adattarsi eccessivamente ai dati di addestramento e si generalizza meglio a nuovi dati.

L'effetto √® un decadimento dei pesi (aggiunge $2\lambda w$) al gradiente della perdita: $$w_{new}= w + \eta \cdot \Delta w - 2 \lambda w$$ e.g: se $\Delta w = 0 \implies w_{new}$ tende sempre di pi√π a decrescere (per questo *decadimento dei pesi*).

```ad-note
title: Bias di linguaggio o di ricerca?
La regolarizzazione non √® un bias di linguaggio, √® un bias di ricerca perch√© non pongo un limite a priori (come per il linguaggio); sposto il limite giocando sul lambda per la ricerca.
```

- Tecnica molto carina ü•∞ perch√© non si limita ai polinomi.
- Qualsiasi sia il bacino di funzioni che sto usando, posso regolarli col solo parametro lambda. Quindi molto vantaggioso.
- La gerarchia di complessit√† varia in funzione di lambda, noto come **coefficiente di regolarizzazione**.

```ad-note
title: Effetti della regolarizzazione su polinomi di grado alto
- Considerando $\lambda = 0$: ![[ex_lbe3.png]] 
Abbiamo gi√† visto che abbiamo $E[w] = 0$ sui dati di training e overfitting.
- Prendendo $\ln\lambda = -18$: ![[ex_tikonov.png]]
Abbiamo evitato l'overfitting per $\lambda = 1.52 \cdot 10^{-8}$
- Prendendo un $\lambda$ troppo alto, $\ln\lambda = 0 \implies \lambda = 1$ ![[ex_tikonov2.png]]
√® troppo rigido, facciamo underfitting.
```

Occorre, quindi, trovare un trade-off: ![[lambda_tradeoff.png]]
abbiamo messo un termine di penalty alla crescita della $w$, come √® facile notare da questa tabella ![[tikonov_table.png]]

### Limitazioni delle Fixed Basis Function 
```ad-def
title: Funzione a base fissa
Una funzione a base fissa, nota anche come funzione a feature fissa, √® una funzione che mappa i dati di input in un insieme fisso di feature, utilizzate come input per un algoritmo di apprendimento automatico. La funzione a base fissa √® progettata in base a conoscenze pregresse o all'esperienza di dominio sul problema in questione ed √® indipendente dai dati utilizzati per l'addestramento o la previsione.
```
Avere una funzione base lungo ogni dimensione di uno spazio di input a $D$-dimensioni ($K$ per LBE) richiede un numero combinatorio di funzioni. Questo problema √® noto come **curse of dimensionality**.
> Se la dimensione delle variabili prese in considerazione √® ampia, per supportare l'apprendimento avremo bisogno di un numero esponenziale di dati.

## Classificazione
Lo stesso modello, usato per la regressione, pu√≤ essere usato per la classificazione. Stavolta non possiamo pi√π prendere valori booleani, ma ci tocca ragionare con i numeri e.g: 0/1, -1/+1
- In questo caso usiamo un iperpiano $wx$ assumendo valori positivi o negativi.
- Sfruttiamo tali modelli per decidere se un punto $x$ appartiene alla zona positiva o negativa dell'iperpiano (per classificarlo).
- Vogliamo trovare $w$ tale che abbiamo una buona accuratezza di classificazione, spostando l'iperpiano.

```ad-def
title: Decision boundary
Il decision boundary √® un confine che separa lo spazio di input in diverse regioni, dove ogni regione √® assegnata a una classe o categoria diversa in un problema di classificazione. 

- Il decision boundary assume forme diverse a seconda dell'algoritmo e della complessit√† del problema di classificazione:
	- Classificazione binaria $\implies$ il decision boundary sar√† una linea retta o una curva. Oppure un iperpiano in uno spazio di input di dimensioni superiori.

L'obiettivo dell'algoritmo di ottimizzazione √® trovare il decision boundary che massimizzi l'accuratezza della classificazione sui dati di addestramento e minimizzi l'errore di classificazione su nuovi dati non visti.
$$w^{T}x = w_{1}x_{1}+ w_{2}x_{2}+ w_{0} = 0$$

![[decision_boundary.png]]
```

La classificazione pu√≤ essere vista come una ripartizione del piano per i valori 0 e 1.
![[threshold_func.png]]
### Classificazione per confini decisionali lineari
La classificazione pu√≤ essere vista come l'allocazione dello spazio di input in **regioni di decisione** (e.g: 0, 1). √à lineare per via di $w^{T}x$, a scalino e unitaria perch√© pu√≤ essere vista come una rete neurale con un neurone.

![[classificazione_lineare.png]]

```ad-def
title: LTU (by Chat-GPT)
√à un neurone artificiale di base utilizzato nelle reti neurali artificiali che impiega una funzione di attivazione a soglia per produrre un'uscita basata su valori di ingresso pesati.
- Una LTU riceve diversi valori di ingresso, li moltiplica per i pesi corrispondenti, li somma e poi applica una funzione di soglia alla somma. Se la somma supera il valore di soglia, il neurone si attiva e produce un'uscita pari a 1, altrimenti produce un'uscita pari a 0.
- La funzione di soglia utilizzata da una LTU pu√≤ essere una funzione a gradini, che produce un'uscita discontinua.
```

```ad-note
title: Threshold (bias $w_{0}$)
Dato un bias $w_{0}$, nell'LTU $$ h(x) = w^{T}x + w_{0}\geq 0 $$ √® equivalente a dire $$h(x) = w^{T}x \geq -w_{0}$$ con $-w_0$ come valore soglia. Questa forma enfatizza il ruolo del bias come valore di soglia per attivare l'uscita +1 del classificatore.
```

#### Esempio spam
Trovare una $h(mail) + 1$ per $spam$ e $-1$ per $not\text{-}spam$.
- Features (variabili) $\phi(mail) = words[0/1]$ $$e.g:\quad \phi_{k}(x) = contain(word_{k})$$
- $w$ √® il contributo in peso delle features in input alla predizione. $$e.g:\quad\text{peso positivo per }free\;money,\text{ negativo per }.unipi$$
- $x^{T}w$ √® la combinazione pesata.
- $h_{w}(x)$ fornisce la soglia per decidere se √® spam o meno. $$h_{w}(x) = \text{sign}\left( \sum\limits_{k}w_{k}\phi_{k}(x) \right) [> 0 \implies +1 = Spam]$$

### Il problema dell'apprendimento per classificatori lineari
Assumendo di usare i minimi quadrati, dati $l$ esempi di training, vogliamo trovare $w$ in modo tale da minimizzare la somma residua dei quadrati (questa √® LS; per la media, cio√® LMS,  bisogna dividere per $l$) $$E[w] = \sum\limits_{p=1}^{l}\left( y_{p}- {x_{p}^{T}w} \right)^{2} = \left\Vert y - Xw\right\Vert ^ 2$$ 

- In $E[w]$ non usiamo la forma $h(x)$ per la regressione, perch√© altrimenti l'errore diventerebbe non differenziabile.
- L'errore minimo:
	- Se $y_{p}= 1 \implies x_{p}^{T}w \to 1$
	- Se $y_{p}\in\{0,-1\}\implies x_{p}^{T}\to 0/-1$

In pi√π abbiamo l'algoritmo di discesa del gradiente (iterativo) che ci indica la direzione lungo la quale spostare (inclinare) l'iperpiano per la classificazione dei valori. 
$$\Delta w_{i}= - \frac{\partial}{\partial w_{i}} E[w] = \sum\limits_{p=1}^{l}(y_{p}- x_{p}^{T}w)\cdot x_{p,i}\quad i=0\ldots n$$

![[deltaW1.png]]

Se classificato male (perch√© il target √® $+1$) aggiorniamo la configurazione dei suoi parametri liberi in modo da non commettere lo stesso errore, per la regola di correzione dell'errore. Per fare ci√≤ incrementiamo i parametri (con $\eta$) fino al *delta* (quindi un valore positivo).

![[deltaW2.png]]

Ora √® corretto.

n.b: Per avere $\Delta w_i$ positivo occorre alzare i pesi üèãÔ∏è‚Äç‚ôÄÔ∏è.

```ad-def
title: Accuratezza
Media dei pattern correttamente classificati $$\text{Accuracy} = \frac{l - \text{num\_err}}{l}$$ $$\text{mean\_{}err} = \frac{1}{l}\underbrace{\sum\limits_{p=1}^{l}L\left( h(x_{p}),d_{p} \right)}_{\text{num\_{}err}}$$
$$L\left( h(x_{p}),d_{p} \right) = \begin{cases}
0\quad&h(x_{p}) = d_{p} \\
1\quad &o/w
\end{cases}$$
```

#### Congiunzioni con i modelli lineari
Consideriamo una $h$ s√¨ fatta
$$h(x) = \begin{cases}
1\quad &wx + w_{0}\geq0 \\
0\quad &o/w
\end{cases}$$ 
- con quattro variabili: $$x_{1}\land x_{2}\land x_{4}\iff y$$ $$\begin{align*}
1 x_{1}+ 1 x_{2}+ 0 x_{3} + 1 x_{4} &> 2\\
1 x_{1} + 1 x_{2} + 0 x_{3}+ 1 x_{4} &\geq 2.5
\end{align*}$$
- con due variabili: $$x_{1}\land x_{2}\iff y$$ $$\begin{align*}
1x_{1}+ 1x_{2} &> 1\\
1x_{1}+ 1x_{2}&\geq 1.5
\end{align*}$$ 
![[ExCongiunzioni_ModelloLineare.png]]

```ad-warning
title: Limitazioni
In geometria, due insiemi di punti in un grafico bidimensionale sono **linearmente separabili** quando: 
- I due inisiemi di punti possono essere completamente separati da una singola retta.
- Se si, allora possiamo fornire una soluzione esatta, altrimenti nada.

In generale, due gruppi sono linearmente separabili nello spazio $n$-dimensionale se possono essere separati da un iperpiano $(n-1)$-dimensionale.
```