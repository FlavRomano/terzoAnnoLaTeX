## Realizzazione degli operatori relazionali
### Proiezione
Osserviamo il caso con **DISTINCT**, l'approccio è basato sull'ordinamento:

```sql
SELECT DISTINCT PROVINCIA
FROM STUDENTI R
```

1. Si legge **R** e si scrive **T** che contiene **solo gli attributi della select**
2. Si ordina **T** su **tutti gli attributi**
3. Si **eliminano i duplicati** (che saranno consecutivi)

### Restrizione con condizione semplice
```sql
SELECT *
FROM STUDENTI R
WHERE R.Provincia = 'PI'
```

- **Senza indice** il DBMS dovrà eseguire una scansione completa della tabella per trovare le righe che soddisfano il criterio.
	- cioè leggere ogni riga di Studenti e confrontare il valore della colonna Provincia con PI
	- questo processo è lento se la tabella contiene un grande numero di righe $$Npag(R)$$
- **Con indice [[B-albero#$B {+}$-Alberi|B+-albero]]** la query può essere ottimizzata. Il DBMS userà l'indice per trovare le righe in cui il valore della colonna Provincia è uguale a PI
	- l'indice contiene solo i valori delle chiavi e i puntatori alle righe corrispondenti
	- costa complessivamente $$CI+CD$$
		- dove $CI$ è il costo dell'indice e $CD$ il costo di accesso ai dati.

### Operazioni di aggregazione
#### Senza [[GROUPBY]]
Si visitano i dati e si calcolano le funziondi di aggregazione 
e.g:
```sql
SELECT COUNT(*)
FROM PERSONE
```
#### Con [[GROUPBY]]
1. Si ordinano i dati sugli attributi del Group by
2. Si visitano i dati 
3. Per ogni gruppo si calcolano le funzioni di aggregazione

e.g 
```sql
SELECT COGNOME, COUNT(COGNOME)
FROM PERSONE
GROUP BY COGNOME
```

### Giunzione
![[Pasted image 20231031095644.png]]

Consideriamo una classica [[JOIN SQL]]:

```sql
SELECT *  
FROM STUDENTI S, ESAMI E 
WHERE S.Matricola=E.Matricola
```

Quando parlammo del [[Theta-join]] abbiamo detto è una selezione di alcune righe del prodotto cartesiano.
- $R\times S$ è grande, quindi $R\times S$ seguito da una restrizione è inefficiente
	- bisogna fare molti confronti

Una cosa non banale è l'ordine degli operandi:
- il join è commutativo, perché il risultato finale rimane invariato anche con gli operandi scambiati di posto
- tuttavia dal punto di vista fisico può deteriorare le prestazioni e cambiare l'ordine delle ennuple

### Nested loops
Consideriamo due relazioni:
1. **$R$** relazione esterna (al loop)
2. **$S$** relazione interna (al loop)

```py
for record_r in R:
	for record_s in S:
		if record_r[i] == record_s[j]:
			"""aggiungi <r,s> al risultato"""
```

Il costo di esecuzione dipende dallo spazio disponibile in memoria centrale:

- al **caso base** in cui vi è **un buffer** per **$R$** e **un buffer** per **$S$**
	1. Bisogna leggere una volta $R$ 
	2. Bisogna leggere **$Nrec(R)$** volte $S$, ovvero tante volte quante sono le tuple della **relazione esterna** $$Npag(R) + Nrec(R) * Npag(S)\quad \text{Operazioni I/O}$$
	- Per ogni record della pagina che ho caricato **devo richiedere il numero di pagine di S** 
- Se è possibile allocare **$Npag(S)$** buffer per la **relazione interna** il costo si riduce a $$Npag(R) + Npag(S)$$

#### Esempio
Consideriamo il join fra **$Dipartimenti$** e **$Impiegati$** ($DipImp=NumDip$) con $$Npag(Dipartimenti) = 20,\quad Nrec(Dipartimenti) = 100$$
$$Npag(Impiegati) = 1000,\quad Nrec(Impiegati) = 10000$$ supponendo di essere al caso base (cioè un buffer per ciascuna relazione)

- Nel caso in cui **Dipartimenti** fosse la **relazione esterna** $$Npag(Dipartimenti) + Nrec(Dipartimenti) * Npag(Impiegati)$$ $$ 20 + 100 * 1000 = \textbf{100.020}\;\text{operazioni I/O}$$
- Nel caso in cui **Impiegati** fosse la **relazione esterna** $$Npag(Impiegati) + Nrec(Impiegati) * Npag(Dipartimenti)$$ $$ 1000 + 10000 * 20 = \textbf{201.000}\;\text{operazioni I/O}$$

Tornando alla teoria, in generale **per ogni record** della relazione esterna **$R$** si visita **tutta la relazione interna $S$**. Questo implica un costo del tipo $$Npag(R) + Nrec(R) * Npag(S)$$
$$\approx Npag(R) * \underline{\frac{{Nrec(R)}}{{Npag(R)}}} * Npag(S)$$

Con **$S$ esterna**:
$$Npag(S) + Nrec(S) * Npag(R)$$
$$\approx Npag(S) * \frac{{Nrec(S)}}{{Npag(S)}} * Npag(R)$$

Osserviamo che vale la seguente disuguaglianza:
$$\underline{\frac{{Nrec(R)}}{{Npag(R)}}} < \frac{{Nrec(S)}}{{Npag(S)}}$$
quindi ==si sceglierà $R$ come **esterna** e $S$ come **interna** se== $$Nrec(R) * Npag(S) < Nrec(S) * Npag(R)$$ 
> cioè solo se le tuple di **$R$** sono **più grandi** di quelle di **$S$**

Questo implica dire che ==come relazione esterna conviene mettere quella con **record più lunghi/grandi**==.

#### Cammini di accesso
L'ordine con cui vengono generate le tuple del risultato **coincide** con l'ordine eventualmente presente nella **relazione esterna**

![[Pasted image 20231031112447.png]]

In questo caso **$R$** è nel **ciclo for più esterno**, pertanto l'output sarà **ordinato per la chiave primaria di $R$**.
Questo è molto importante, basti pensare a una situazione in cui la query contiene **ORDER BY R.A**.

Abbiamo due varianti di nested loop:
1. [[Nested loop a pagine]]
2. [[Nested loop a indice]]

### Sort-merge
Il sort-merge join è applicabile
> ==quando entrambi gli insiemi di tuple in input **sono ordinati** sugli attributi di join==.

L'algoritmo sfrutta questo fatto dell'ordinamento per evitare **confronti inutili**, riducendo il numero di letture a $$Npag(R) + Npag(S)$$ se si accede sequenzialmente alle due relazioni.

oss: Ogni pagina di $R$ e di $S$ viene trasferita al massimo una volta.

Quindi, per $R$ si può fare sort-merge se:
1. $R$ è fisicamente **ordinata** sugli **attributi di join**
2. Esiste un **indice** sugli **attributi di join** di $R$

Vale analogamente per $S$

![[Pasted image 20231031120035.png]]

```py
r, s = first(R), first(S)
while r in R and s in S:
	if r.i == s.i:
		"""
		avanza r ed s fino a che r.i ed s.i non cambiano (entrambe),
		aggiungendo ciascun <r,s> al risultato
		"""
	elif r.i < s.i:
		"""avanza r  dentro R"""
	elif r.i > s.i:
		"""avanza s  dentro S"""
```

In pratica si visitano $R$ ed $S$ in parallelo.