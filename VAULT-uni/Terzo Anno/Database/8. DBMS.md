## Introduzione
Un DBMS è un sistema software che gestisce grandi quantità di dati persistenti e condivisi.

Le due caratteristiche principali di un DBMS sono
1. **Persistenza**
2. **Condivisione**

per garantire queste due caratteristiche, un DBMS deve fornire meccanismi per
- **affidabilità dei dati** (fault tolerance)
- **controllo degli accessi**
- **controllo della concorrenza** e.g operazioni simultanee da parte di due utenti

### Condivisione dei dati
La **condivisione dei dati** permette di ridurre la ridondanza (dovuta a copie multiple dello stesso dato) che porta spesso a 
- **sprechi di memoria**
- **inconsistenze** tra le diverse copie se le modifiche non vengono **propagate correttamente**

### Modello dei dati
Il DBMS può essere visto come una **collezione di dati** che modellano una certa porzione della realtà d'interesse.

Un **[[modello di dati]]** è definito dall'**astrazione logica** con cui i dati vengono resi disponibile all'utente.
Sono molto importanti i **meccansmi** usati per strutturare i dati, esistono modelli in cui i dati sono descritti: 
- SOLO sotto forma di alberi
- di grafi
- di oggetti complessi 
- di relazioni

### Indipendenza fisica e logica
Tra gli obiettivi principali del DBMS c'è
- l'**indipendenza fisica**
	- l'**organizzazione fisica** dei dati dipende da considerazioni legate all'efficienza, una modifica all'organizzazione fisica **non deve avere effetti collaterali** sui programmi applicativi
- l'**indipendenza logica**
	- posso rappresentare le tabelle in un determinato modo, l'utente del database è all'oscuro dell'implementazione
	- accedere ai dati logici indipendentemente dalla rappresentazione fisica.

### Architettura semplificata


![[Pasted image 20230829174402.png]]

Un DBMS è organizzato su **due livelli**

![[Pasted image 20230829174453.png]]

1. **Macchina logica**
	- dedicata all'interpretazione e l'esecuzione di comandi sql
	- utilizza gli operatori forniti dalla macchina fisica per eseguire comandi sql
2. **Macchina fisica**
	- gestisce la memoria permanente e le strutture per la memorizzazione e recupero dei dati

## Gerarchia delle memoria
La memoria di un sistema di calcolo è **organizzata gerarchicamente**
- al **livello più alto** abbiamo memorie piccole e veloci
- scendendo **più in basso** le memorie diventano più grandi e lente

Dato un indirizzo di memoria, le **prestazioni** si misurano in termini di **tempo di accesso** cioè la somma tra 
- **latenza**, quanto tempo impiego per accedere al primo byte
- **tempo di trasferimento**, quanto tempo impiego per muovere i dati

$$\text{Tempo di accesso} = latenza + \frac{\text{dimensione dati da trasferire}}{\text{velocità di trasferimento}}$$

## Implicazioni
- Un DBMS risiede su dischi
- I dati devono essere trasferiti dalla memoria centrale per essere elaborati dal DBMS
- Il trasferimento avviene per **[[pagina|pagine]]**, non per singole tuple
- Le operazioni di I/O fanno bottleneck, bisogna ottimizzare l'implementazione fisica:
	- organizzare efficientemente le tuple su disco
	- strutture di accesso efficienti
	- gestione efficiente dei buffer in memoria
	- strategie di esecuzione efficienti per le query

### Hard disk
È un dispositivo che conserva le informazioni sotto forma magnetica
- su supporto rotante a forma di piatto
- su cui agiscono testine di lettura e scrittura

![[Pasted image 20230829180019.png]]

- una **traccia** è organizzata in **settori** (di dimensione fissa)
- i **settori** sono raggruppati logicamente in **[[pagina|blocchi]]** (unità di trasferimento)

Trasferire una [[pagina]] richiede
- un tempo di **posizionamento testine**
- un tempo di **latenza**
- un tempo di **trasferimento** (trascurabile)

## Gestore memoria permanente
![[Pasted image 20230829183411.png]]

Fornisce un'astrazione della memoria permanente in termini di
- file (pagine fisiche) di grandezza prefissata
- nascondendo le caratteristiche dei dischi al sistema operativo.

## Gestore del buffer
![[Pasted image 20230829183400.png]]

Gestisce uno spazio della **memoria temporanea** destinato a contenere **un insieme di pagine fisiche** della **memoria permanente**

Si preoccupa del trasferimento delle pagine tra **memoria temporanea** e **memoria permanente**
- offre agli altri livelli del sistema una visione della **memoria permanente** come **insieme di pagine** utilizzabili dalla **memoria temporanea**
- astrae l'operazione da quando esse **vengano trasferite** dalla memoria permanente al buffer e viceversa

Il buffer può contenere molte pagine ed è utile per evitare riletture dal disco (se disponibili ovviamente).
Gli aggiornamenti ai dati **vengono effettuati nel buffer** e vengono **riportati su disco** solo quando richiesto (e.g il protocollo lo richiede oppure il buffer deve essere liberato)

Quando un **record viene inserito** il sistema gli assegna un id che diventa il riferimento da usare nelle strutture dati. Finché il record esiste nel DBMS il suo id rimane invariato.

### Area delle pagine
Ogni pagina contiene le variabili:
- **Pin count**, un contatore che viene incrementato/decrementato quando una [[pagina]] viene richiesta/rilasciata
	- contiene il numero di applicazioni che stanno utilizzando quella pagina
- **Dirty bit**, indica se la pagina è stata modificata o meno
	- la componente che ha eseguito la modifica chiede al buffer di aggiornarla (nella pagina modificata)

![[Pasted image 20230829183301.png]]

### Politiche di rimpiazzamento
Nei sistemi operativi viene adottata la politica **LRU** (least recently used)
- viene rimpiazzata la pagina **che non viene usata da più tempo**
- c'è infatti alta probabilità che essa non serva più all'utente

Nei DBMS non è sempre una buona scelta
- per alcune query il **pattern di accesso** ai dati è noto
- quindi abbiamo un'ottima informazione per fare scelte più accurate (rispetto all'LRU) e aumentare le prestazioni

L'hit-ratio (rapporto tra le richieste che non richiedono I/O e le richieste totali) indicano quanto è buona una politica di rimpiazzamento, perché è un buon indice per dirci quante volte accede in memoria centrale.

> e.g: esistono algoritmi di Join che scandiscono $N$ volte le tuple di una relazione
> - quindi sarebbe conveniente utilizzare una politica di rimpiazzamento che rimpiazzi quella più recente **MRU** (most recently used)

### Struttura di una pagina
Fisicamente una [[pagina]] è 
- un insieme (di dimensione fissa) di caratteri

Logicamente contiene
- informazioni di servizio
- un'area che contiene le stringhe che rappresentano i record

Tipicamente questo è il formato di una pagina:

![[Pasted image 20230829184530.png]]
Come si identifica un record all'interno di una pagina?

L'header **directory** contiene un **puntatore per ogni record della pagina**
- l'**RID** (identificatore di un record) è formato dalla coppia
	- **PID**, identificatore della pagina
	- **SLOT**, posizione all'interno della pagina

e.g Se il record si sposta nella pagina (pensiamo a una modifica che ne cambi la lunghezza) allora non è necessario cambiare RID (basta solo modificare il contenuto del record)

![[Pasted image 20230829184848.png]]

quindi è possibile individuare velocemente un record e anche riallocare la pagina **senza modificare il RID**

## Gestore strutture di memorizzazione
![[Pasted image 20230829183411.png]]

Offre agli altri livelli del sistema una visione dei dati permanenti organizzati in **collezioni di record e indici**, in questo modo astrae dai supporti di memoria in cui sono memorizzati in memoria permanente.

### Tipi di organizzazione
Un'organizzazione dei dati è un **insieme di algoritmi** per **gestire le operazioni su una collezione di record** in grado di:
- individuare la pagina in cui inserire un nuovo record (quando questo viene aggiunto alla collezione)
- gestire situazioni in cui una sequenza di modifiche (cancellazioni o inserimenti) rendono una pagina troppo vuota o troppo piena

A cornice di tutto vengono scelte delle strutture ausiliarie per facilitare l'esecuzione delle ricerche.

- **[[Organizzazione seriale]]**
	- i dati sono memorizzati in modo **disordinato** uno dopo l'altro.
	- semplice e a basso costo di memoria
	- poco efficiente, va bene per pochi dati
- **[[Organizzazione sequenziale]]**
	- i dati sono memorizzati in modo **ordinato**, sul valore di uno o più attributi
	- ricerche più veloci
	- le inserzioni fanno perdere l'ordinamento
- **Per chiave**
	- una volta noto il valore di una chiave
	- per trovare il record di una tabella basta qualche accesso al disco (idealmente uno solo)
	- come alternative: metodo [[Metodo procedurale (o hash)|procedurale]] (hash) o [[Metodo tabellare|tabellare]] (indice), organizzazione statica o dinamica.

## Ordinamento
Ordinare gli archivi è **fondamentale**
- fare raggruppamento risulta più semplice se **ho le ennuple già ordinate**
- anche interrogare in base all'ordine ([[ORDER BY]])
- anche eliminare duplicati con `DISTINCT`

L'algoritmo di Merge-sort a Z vie costa $\Theta(N\log(N))$

### Merge Sort a Z vie
È l'algoritmo più utilizzato dai DBMS.

Supponiamo di dover ordinare un input che consiste di un file di $NP$ [[pagina|pagine]] e di avere a disposizione solo $NB<NP$ *buffer* in memoria centrale.

L'[[Z-way Merge sort Z=2|algoritmo]] opera in due fasi:
1. **Sort interno**, dove
	- si leggono una alla volta le **pagine del file**
	- i record di ogni pagina **vengono ordinati** facendo uso di un **algoritmo di sort interno** e.g Quicksort
	- **ogni pagina ordinata**, detta anche *run*, viene **scritta su un disco** in un file temporaneo
2. **Merge**, dove
	- si fanno una o più passi di [[Z-way Merge sort Z=2#Fusione z-way|fusione]] per **unire le run**
	- fino a quando non si produce un'unica run **mergiata**

Dopo aver osservato la [[Z-way Merge sort Z=2#Complessità|complessità per il caso base]], generalizziamolo:
- **nel sort interno** abbiamo a disposizione $NB$ buffer 
- è possibile **ordinare** $NP$ **pagine** alla volta (anziché una) quindi il **numero di passi di fusione** è $$\#fusione = \left\lceil \lg \frac{NP}{NB}\right\rceil$$ quindi il costo complessivo diventa $$2 \cdot NP \cdot \left(\left\lceil \lg \frac{NP}{NB}\right\rceil+1\right)$$

e.g: con $NP = 8000$ pagine e $NB=3$, si hanno ora $$2\cdot 8000 \cdot \left(\left\lceil \lg \frac{8000}{3}\right\rceil + 1\right)\sim 208'000\text{ operazioni di I/O}$$ cioè $4'480\text{ sec}=1.15$ ore

Un miglioramento sostanziale lo si ottiene con $NB > 3$ **buffer a disposizione**:
- si **fondono $NB-1$ run**  alla volta (ricordiamo che 1 buffer è per l'output)
- il che rende il numero di passi **logaritmico in $NB-1$** $$2 \cdot NP \cdot \left(\left\lceil \log_{NB-1} \frac{NP}{NB}\right\rceil + 1\right)$$ in quanto ad ogni passo il numero di run **si riduce di un fattore $N-1$**

Infatti con $NP = 8000$ e $NB = 11$ si hanno solo $$2 \cdot 8000 \cdot \left(\left\lceil \log_{63} \frac{8000}{11}\right\rceil + 1\right)\sim 64'000 \text{ operazioni di I/O}$$ arrivando a un tempo di $21.3$ minuti

## Realizzazione degli operatori relazionali
### Proiezione
Osserviamo il caso con **DISTINCT**, l'approccio è basato sull'ordinamento:

```sql
SELECT DISTINCT PROVINCIA
FROM STUDENTI R
```

1. Si legge **R** e si scrive **T** che contiene **solo gli attributi della select**
2. Si ordina **T** su **tutti gli attributi**
3. Si **eliminano i duplicati** (che saranno consecutivi)

### Restrizione con condizione semplice
```sql
SELECT *
FROM STUDENTI R
WHERE R.Provincia = 'PI'
```

- **Senza indice** il DBMS dovrà eseguire una scansione completa della tabella per trovare le righe che soddisfano il criterio.
	- cioè leggere ogni riga di Studenti e confrontare il valore della colonna Provincia con PI
	- questo processo è lento se la tabella contiene un grande numero di righe $$Npag(R)$$
- **Con indice [[B-albero#$B {+}$-Alberi|B+-albero]]** la query può essere ottimizzata. Il DBMS userà l'indice per trovare le righe in cui il valore della colonna Provincia è uguale a PI
	- l'indice contiene solo i valori delle chiavi e i puntatori alle righe corrispondenti
	- costa complessivamente $$CI+CD$$
		- dove $CI$ è il costo dell'indice e $CD$ il costo di accesso ai dati.

### Operazioni di aggregazione
#### Senza [[GROUPBY]]
Si visitano i dati e si calcolano le funziondi di aggregazione 
e.g:
```sql
SELECT COUNT(*)
FROM PERSONE
```
#### Con [[GROUPBY]]
1. Si ordinano i dati sugli attributi del Group by
2. Si visitano i dati 
3. Per ogni gruppo si calcolano le funzioni di aggregazione

e.g 
```sql
SELECT COGNOME, COUNT(COGNOME)
FROM PERSONE
GROUP BY COGNOME
```

### Giunzione
![[Pasted image 20231031095644.png]]

Consideriamo una classica [[JOIN SQL]]:

```sql
SELECT *  
FROM STUDENTI S, ESAMI E 
WHERE S.Matricola=E.Matricola
```

Quando parlammo del [[Theta-join]] abbiamo detto è una selezione di alcune righe del prodotto cartesiano.
- $R\times S$ è grande, quindi $R\times S$ seguito da una restrizione è inefficiente
	- bisogna fare molti confronti

Una cosa non banale è l'ordine degli operandi:
- il join è commutativo, perché il risultato finale rimane invariato anche con gli operandi scambiati di posto
- tuttavia dal punto di vista fisico può deteriorare le prestazioni e cambiare l'ordine delle ennuple

### Nested loops
Consideriamo due relazioni:
1. **$R$** relazione esterna (al loop)
2. **$S$** relazione interna (al loop)

```py
i,j = 0
for record_r in R:
	for record_s in S:
		if record_r[i] == record_s[j]:
			res.append(<r,s>)
		i += 1
		j += 1
```

Il costo di esecuzione dipende dallo spazio disponibile in memoria centrale:

- al **caso base** in cui vi è **un buffer** per **$R$** e **un buffer** per **$S$**
	1. Bisogna leggere una volta $R$ 
	2. Bisogna leggere **$Nrec(R)$** volte $S$, ovvero tante volte quante sono le tuple della **relazione esterna** $$Npag(R) + Nrec(R) * Npag(S)\quad \text{Operazioni I/O}$$
	- Per ogni record della pagina che ho caricato **devo richiedere il numero di pagine di S** 
- Se è possibile allocare **$Npag(S)$** buffer per la **relazione interna** il costo si riduce a $$Npag(R) + Npag(S)$$

#### Esempio
Consideriamo il join fra **$Dipartimenti$** e **$Impiegati$** ($DipImp=NumDip$) con $$Npag(Dipartimenti) = 20,\quad Nrec(Dipartimenti) = 100$$
$$Npag(Impiegati) = 1000,\quad Nrec(Impiegati) = 10000$$ supponendo di essere al caso base (cioè un buffer per ciascuna relazione)

- Nel caso in cui **Dipartimenti** fosse la **relazione esterna** $$Npag(Dipartimenti) + Nrec(Dipartimenti) * Npag(Impiegati)$$ $$ 20 + 100 * 1000 = \textbf{100.020}\;\text{operazioni I/O}$$
- Nel caso in cui **Impiegati** fosse la **relazione esterna** $$Npag(Impiegati) + Nrec(Impiegati) * Npag(Dipartimenti)$$ $$ 1000 + 10000 * 20 = \textbf{201.000}\;\text{operazioni I/O}$$

Tornando alla teoria, in generale **per ogni record** della relazione esterna **$R$** si visita **tutta la relazione interna $S$**. Questo implica un costo del tipo $$Npag(R) + Nrec(R) * Npag(S)$$
$$\approx Npag(R) * \underline{\frac{{Nrec(R)}}{{Npag(R)}}} * Npag(S)$$

Con **$S$ esterna**:
$$Npag(S) + Nrec(S) * Npag(R)$$
$$\approx Npag(S) * \frac{{Nrec(S)}}{{Npag(S)}} * Npag(R)$$

Osserviamo che vale la seguente disuguaglianza:
$$\underline{\frac{{Nrec(R)}}{{Npag(R)}}} < \frac{{Nrec(S)}}{{Npag(S)}}$$
quindi ==si sceglierà $R$ come **esterna** e $S$ come **interna** se== $$Nrec(R) * Npag(S) < Nrec(S) * Npag(R)$$ 
> cioè solo se le tuple di **$R$** sono **più grandi** di quelle di **$S$**

Questo implica dire che ==come relazione esterna conviene mettere quella con **record più lunghi/grandi**==.

#### Cammini di accesso
L'ordine con cui vengono generate le tuple del risultato **coincide** con l'ordine eventualmente presente nella **relazione esterna**

![[Pasted image 20231031112447.png]]

In questo caso **$R$** è nel **ciclo for più esterno**, pertanto l'output sarà **ordinato per la chiave primaria di $R$**.
Questo è molto importante, basti pensare a una situazione in cui la query contiene **ORDER BY R.A**.

### Nested loop a pagine (page nested loop)
Molti DBMS utilizzano questa variante dove
- rinunciamo all'ordine imposto dalla relazione esterna
- per eseguire il **join** di **tutte le tuple in memoria** 
	- prima di **richiedere nuove pagine** della **relazione interna**

```py
for page_r in R:
	for page_s in S:
		"""esegui il join di tutte le tuple in page_r e page_s"""
```

![[Pasted image 20231031113101.png]]

Come è facile notare, prima $NP(R)$ era il numero di record $Nrec$ della relazione esterna $R$.
Questa strategia è molto versatile, infatti può essere usata anche nel caso in cui a $R$ siano **assegnati più buffer**.

### Nested loop con indice (index nested loop)