```ad-def
title: Agenti risolutori "classici"
Gli agenti risolutori di problemi "classici" assumono:
- Ambienti completamente osservabili e deterministici
- Si trovano nelle condizione di produrre offline una sequenza di azioni che può essere eseguito senza imprevisti per raggiungere l'obiettivo.
```

La ricerca sistematica (o euristica) nello spazio di stati è troppo costosa $\implies$ metodi di ricerca locale.

## Ricerca locale
```ad-warning
title: Assunzioni per la ricerca locale
Fin'ora abbiamo visto algoritmi che esplorano gli spazi di ricerca alla ricerca di un goal e restituiscono un cammino soluzione.
Tuttavia a volte lo stato goal è la soluzione del problema.
```

Gli algoritmi di ricerca locale sono adatti per problemi in cui:
- La sequenza di azioni non è importante, è importante unicamente lo stato goal.
- Tutti gli elementi della soluzione sono nello stato ma alcuni vincoli sono violati. Ci interessa ottenere la soluzione, non il path.

```ad-def
title: Algoritmi di ricerca locale
- Non sono sistematici
- Tengono traccia solo del nodo corrente e si spostano su nodi adiacenti (al contrario di un algoritmo globale).
- Non tengono traccia dei cammini (non servono in uscita).
	1. Sono efficienti in termini di occupazione di memoria
	2. Possono trovare soluzioni ragionevoli anche in spazi molto grandi e infiniti (e.g spazi continui).
- Utili per risolvere problemi di ottimizzazione:
	- Stato migliore secondo una funzione obiettivo $f$.
	- Stato di costo minore (ma non il path, cerchiamo lo stato di costo minore, non il percorso di costo minore).

e.g minimizzare il numero di regine sotto attacco.

```

### Panorama dello spazio degli stati
Uno stato ha una posizione sulla superficie e un'altezza che corrisponde al valore della funzione di valutazione (funzione obiettivo).

![[panorama_sstati.png]]

$$f =\text{euristica di costo della funzione obiettivo}$$ Ci spostiamo di stato in stato e ogni volta viene rivalutata la funzione obiettivo. Un algoritmo provoca movimento sulla superficie.
- Vogliamo trovare l'avvallamento più basso (e.g minimizzare il costo) o il picco più alto (e.g massimo di un obiettivo).

### Ricerca in salita (Hill climbing, steepest-ascent/descent)
L'algoritmo di ricerca hill-climbing (versione steepest-ascent) non è altro che un ciclo che si muove continuamente in direzione di un valore crescente, cioè in salita. 
- Termina quando raggiunge un "picco" in cui nessun vicino ha un valore superiore. 
- L'algoritmo non mantiene un albero di ricerca, quindi la struttura dei dati per il nodo corrente deve registrare solo lo stato e il valore della funzione obiettivo. 
- L'Hill climbing non guarda oltre i vicini immediati dello stato corrente. È come cercare di trovare la cima dell'Everest in una fitta nebbia mentre si soffre di amnesia.

Abbiamo diverse implementazioni di questo algoritmo di ricerca che si differenziano per il modo in cui viene scelto un nodo tra quelli generati (in modo tale da migliorare la valutazione dello stato attuale):
- Seleziono il migliore $\implies$ Hill climbing a salita ripida.
- Seleziono uno a caso (tra quelli che salgono) $\implies$ Hill climbing stocastico.
- Seleziono il primo generato $\implies$ Hill climbing con prima scelta.

Se non ci sono stati successori migliori, allora l'algoritmo termina con fallimento.

```ad-note
title: Greediness
L'Hill Climbing è talvolta chiamato ricerca locale greedy, in quanto afferra uno stato di buon vicinato senza pensare a dove andare dopo. L'Hill Climbing fa spesso rapidi progressi verso una soluzione, perché di solito è abbastanza facile migliorare uno stato negativo. 
```

```ad-warning
title: Quando si interrompe l'hill climbing?
- **Massimi locali**. Un massimo locale è un picco che è più alto di ciascuno dei suoi stati vicini ma più basso del massimo globale. Gli algoritmi di Hill-climbing che raggiungono l'intorno di un massimo locale saranno attratti verso l'alto in direzione del picco, ma saranno poi bloccati senza poter andare da nessuna parte.
- **Creste**. Le creste danno luogo a una sequenza di massimi locali che è molto difficle da percorrere per gli algoritmi greedy.
- **Plateaux**. Un plateau è un'area piatta dello spazio degli stati. Può essere un massimo locale piatto, da cui non esiste un'uscita in salita da cui è possibile progredire. Una ricerca di tipo hill-climbing potrebbe perdersi su un plateau.
```
#### Codice
```python
def hill_climbing(problem):
	current = Node(problem.initial_state)
	while True:
		vicini = [current.child_node(problem, action) 
			for action in problem.actions(current.state)]
		if not vicini:
			# current non ha successori
			# esci e ritorna current
			break
		# scegli il vicino con valore più alto (sulla funzione problem.value)
		vicino = (sorted(vicini, key = lambda x: problem.value(x), reverse = True))[0]
		if problem.value(vicino) <= problem.value(current):
			# non miglioro lo stato
			break
		# il vicino è migliore, aggiorno current
		current = vicino
	return current
	
```

#### Problema delle 8 regine (formulazione a stato completo)
Gli algoritmi di ricerca locale utilizzano in genere una formulazione a stati completi, in cui ogni stato ha 8 regine sulla scacchiera, una per colonna. I successori di uno stato sono tutti i possibili stati generati dallo spostamento di una singola regina in un'altra casella della stessa colonna (quindi ogni stato ha $8 \cdot 7 = 56 successori$). La funzione di costo euristico $h$ (stima euristica del costo $f$) è il numero di coppie di regine che si attaccano a vicenda, direttamente o indirettamente. 

![[8regine_hillclimbing_ex1.png]]
- Il minimo globale di questa funzione è zero, che si verifica solo in presenza di soluzioni perfette. La Figura mostra uno stato con $h = 17$, all'interno delle caselle mostra i valori di tutte le coppie di regine che si attaccano reciprocamente. La figura mostra anche i valori di tutti i suoi successori, con i migliori successori che hanno h=12. Gli algoritmi di Hill-climbing scelgono tipicamente in modo casuale tra l'insieme dei migliori successori, se ce n'è più di uno.

![[8regine_hillclimbing_ex2.png]]
- In questo caso abbiamo $h = 1$, tutti gli stati successori non migliorano la soluzione.
- Per le 8 regine l'algoritmo si blocca l'$86\%$ delle volte.
- Però funziona rapidamente, impiegando in media solo 4 passi quando riesce e 3 quando si blocca. Non male per uno spazio di stati con $8^8 \sim 17$ milioni di stati.

![[8regine_hillclimbing_ex3.png]]
- In questo caso in sole 3 mosse siamo riusciti a minimizzare la funzione obiettivo, passando da $h = 5$ (perché si stanno attaccando 5 coppie) fino a 0 (minimo assoluto).